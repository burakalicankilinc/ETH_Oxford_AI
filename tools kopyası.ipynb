{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reinstall all langchain packages to the latest matching versions\n",
    "#%pip install -U --force-reinstall langchain langchain-community langchain-core langchain-google-genai valyu prophet yfinance matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burakalicankilinc/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessage\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain/chat_models/base.py:452\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    444\u001b[39m     warnings.warn(\n\u001b[32m    445\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    447\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    448\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    449\u001b[39m     )\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    458\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain/chat_models/base.py:476\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m model, model_provider = _parse_model(model, model_provider)\n\u001b[32m    475\u001b[39m creator_func = _get_chat_model_creator(model_provider)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreator_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain/chat_models/base.py:35\u001b[39m, in \u001b[36m_call\u001b[39m\u001b[34m(cls, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[BaseChatModel], **kwargs: Any) -> BaseChatModel:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# TODO: replace with operator.call when lower bounding to Python 3.11\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_core/load/serializable.py:118\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    117\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:825\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    818\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_client = httpx.Client(\n\u001b[32m    819\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    820\u001b[39m         )\n\u001b[32m    821\u001b[39m     sync_specific = {\n\u001b[32m    822\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_client\n\u001b[32m    823\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_httpx_client(\u001b[38;5;28mself\u001b[39m.openai_api_base, \u001b[38;5;28mself\u001b[39m.request_timeout)\n\u001b[32m    824\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    826\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28mself\u001b[39m.root_client.chat.completions\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Annotated, Literal, TypedDict, List\n",
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "# --- LIBRARIES ---\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from pydantic import BaseModel, Field\n",
    "from valyu import Valyu \n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Callable, Generic, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "U = TypeVar(\"U\")\n",
    "\n",
    "@dataclass\n",
    "class IO(Generic[T]):\n",
    "    \"\"\"\n",
    "    A pure description of a side-effectful computation.\n",
    "    Nothing runs until .unsafe_run() is called.\n",
    "    \"\"\"\n",
    "    effect: Callable[[], T]\n",
    "\n",
    "    @staticmethod\n",
    "    def pure(value: T) -> \"IO[T]\":\n",
    "        \"\"\"Lift a pure value into the IO context.\"\"\"\n",
    "        return IO(lambda: value)\n",
    "\n",
    "    @staticmethod\n",
    "    def fail(error: Exception) -> \"IO[Any]\":\n",
    "        \"\"\"Lift an error into the IO context.\"\"\"\n",
    "        def _raise(): raise error\n",
    "        return IO(_raise)\n",
    "\n",
    "    def map(self, f: Callable[[T], U]) -> \"IO[U]\":\n",
    "        \"\"\"Apply a pure function to the result of the effect.\"\"\"\n",
    "        return IO(lambda: f(self.effect()))\n",
    "\n",
    "    def flat_map(self, f: Callable[[T], \"IO[U]\"]) -> \"IO[U]\":\n",
    "        \"\"\"Chain a new effect based on the result of the previous one.\"\"\"\n",
    "        return IO(lambda: f(self.effect()).unsafe_run())\n",
    "\n",
    "    def attempt(self) -> \"IO[T | Exception]\":\n",
    "        \"\"\"Materialize errors into values (Better failure handling).\"\"\"\n",
    "        def _safe_run():\n",
    "            try:\n",
    "                return self.effect()\n",
    "            except Exception as e:\n",
    "                return e\n",
    "        return IO(_safe_run)\n",
    "\n",
    "    def unsafe_run(self) -> T:\n",
    "        \"\"\"The 'Edge' - actually executes the side effects.\"\"\"\n",
    "        return self.effect()\n",
    "\n",
    "# Helper for composing multiple IOs\n",
    "def sequence(ios: list[IO[T]]) -> IO[list[T]]:\n",
    "    def _run_all():\n",
    "        return [io.unsafe_run() for io in ios]\n",
    "    return IO(_run_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentInput(TypedDict):\n",
    "    \"\"\"Simple input state for each subagent.\"\"\"\n",
    "    query: str\n",
    "\n",
    "\n",
    "class AgentOutput(TypedDict):\n",
    "    \"\"\"Output from each subagent.\"\"\"\n",
    "    source: str\n",
    "    result: str\n",
    "\n",
    "\n",
    "class Classification(TypedDict):\n",
    "    \"\"\"A single routing decision: which agent to call with what query.\"\"\"\n",
    "    source: Literal[\"quant\", \"research\"]\n",
    "    query: str\n",
    "\n",
    "\n",
    "class RouterState(TypedDict):\n",
    "    query: str\n",
    "    classifications: list[Classification]\n",
    "    results: Annotated[list[AgentOutput], operator.add]  \n",
    "    final_answer: str\n",
    "\n",
    "class BrownianParams(TypedDict):\n",
    "    mu: float\n",
    "    sigma: float\n",
    "    last_price: float\n",
    "    annual_vol: float\n",
    "    annual_drift: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EFFECT DEFINITIONS (I/O Boundary) ---\n",
    "\n",
    "def fetch_stock_history_io(ticker: str, years: int = 2) -> IO[pd.DataFrame]:\n",
    "    \"\"\"Effect: Network Call to Yahoo Finance.\"\"\"\n",
    "    def _fetch():\n",
    "        end_date = pd.Timestamp.today().normalize()\n",
    "        start_date = end_date - pd.DateOffset(years=years)\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        # Cleanup logic (part of the fetch IO boundary)\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data = data['Close']\n",
    "            if isinstance(data, pd.DataFrame) and ticker in data.columns:\n",
    "                 data = data[ticker]\n",
    "        elif 'Close' in data.columns:\n",
    "            data = data['Close']\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "             data = data.iloc[:, 0]\n",
    "        return data\n",
    "    return IO(_fetch)\n",
    "\n",
    "def run_monte_carlo_io(params: BrownianParams, days: int = 30, scenarios: int = 1000) -> IO[pd.DataFrame]:\n",
    "    \"\"\"Effect: Random Number Generation & Simulation.\"\"\"\n",
    "    def _sim():\n",
    "        mu, sigma, S0 = params['mu'], params['sigma'], params['last_price']\n",
    "        dt = 1\n",
    "        returns = np.random.normal(loc=mu * dt, scale=sigma * np.sqrt(dt), size=(days, scenarios))\n",
    "        price_paths = np.vstack([np.full((1, scenarios), S0), S0 * np.exp(np.cumsum(returns, axis=0))])\n",
    "        return pd.DataFrame(price_paths)\n",
    "    return IO(_sim)\n",
    "\n",
    "def valyu_search_io(query: str) -> IO[dict]:\n",
    "    \"\"\"\n",
    "    Effect: External API Search with Strict Relevance Filters.\n",
    "    Returns a Dictionary (JSON), not a string, to avoid premature formatting.\n",
    "    \"\"\"\n",
    "    def _search():\n",
    "        try:\n",
    "            client = Valyu(api_key=os.environ.get(\"VALYU_API_KEY\"))\n",
    "            \n",
    "            # API-LEVEL FILTERING (The Real Fix)\n",
    "            # max_num_results=3: Only get the top 3 most relevant hits.\n",
    "            # response_length=\"short\": Asks API for concise summaries (~25k chars total).\n",
    "            return client.search(\n",
    "                query=query,\n",
    "                max_num_results=3, \n",
    "                response_length=\"short\"  \n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return an error dict so the pure logic can handle it gracefully\n",
    "            return {\"error\": str(e), \"results\": []}\n",
    "            \n",
    "    return IO(_search)\n",
    "\n",
    "def prophet_predict_io(df: pd.DataFrame, days: int = 30) -> IO[pd.DataFrame]:\n",
    "    \"\"\"Effect: Heavy Computation / Model Training.\"\"\"\n",
    "    def _train_and_predict():\n",
    "        m = Prophet(daily_seasonality=True)\n",
    "        m.fit(df)\n",
    "        future = m.make_future_dataframe(periods=days)\n",
    "        forecast = m.predict(future)\n",
    "        return forecast\n",
    "    return IO(_train_and_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PURE DOMAIN TYPES & LOGIC ---\n",
    "\n",
    "class BrownianParams(TypedDict):\n",
    "    mu: float\n",
    "    sigma: float\n",
    "    last_price: float\n",
    "    annual_vol: float\n",
    "    annual_drift: float\n",
    "\n",
    "def calculate_brownian_params_pure(prices: pd.Series) -> BrownianParams:\n",
    "    \"\"\"Pure: Extract statistical parameters from data.\"\"\"\n",
    "    if len(prices) < 2:\n",
    "        raise ValueError(\"Not enough data\")\n",
    "\n",
    "    daily_returns = ((prices / prices.shift(1)) - 1).dropna()\n",
    "    mu = np.mean(daily_returns)\n",
    "    sigma = np.std(daily_returns)\n",
    "    last_price = float(prices.iloc[-1])\n",
    "    \n",
    "    return {\n",
    "        \"mu\": mu,\n",
    "        \"sigma\": sigma,\n",
    "        \"last_price\": last_price,\n",
    "        \"annual_vol\": sigma * np.sqrt(252),\n",
    "        \"annual_drift\": mu * 252\n",
    "    }\n",
    "\n",
    "def format_brownian_output_pure(sim_df: pd.DataFrame, ticker: str, params: BrownianParams) -> str:\n",
    "    \"\"\"Pure: Format the simulation results into a detailed table.\"\"\"\n",
    "    days = sim_df.shape[0]\n",
    "    future_dates = pd.date_range(start=pd.Timestamp.today(), periods=days, freq='B')\n",
    "    \n",
    "    stats_df = pd.DataFrame({\n",
    "        'Date': future_dates,\n",
    "        'Mean': sim_df.mean(axis=1),\n",
    "        'Low (0.1%)': sim_df.quantile(0.001, axis=1),\n",
    "        'High (99.9%)': sim_df.quantile(0.999, axis=1)\n",
    "    })\n",
    "    \n",
    "    # Weekly snapshots\n",
    "    display_df = stats_df.iloc[::5].copy()\n",
    "    \n",
    "    # Formatting dates to be shorter\n",
    "    display_df['Date'] = display_df['Date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Create ASCII table\n",
    "    table_str = display_df.to_string(index=False, float_format=\"%.2f\")\n",
    "    \n",
    "    return (f\"Brownian Motion Analysis for {ticker}:\\n\"\n",
    "            f\"--- TECHNICAL PARAMETERS ---\\n\"\n",
    "            f\"Annualized Volatility: {params['annual_vol']:.2%}\\n\"\n",
    "            f\"Annualized Drift: {params['annual_drift']:.2%}\\n\"\n",
    "            f\"--- FORECAST TABLE (Weekly Snapshots) ---\\n\"\n",
    "            f\"```text\\n{table_str}\\n```\")  # <--- WRAPPED IN CODE BLOCK\n",
    "\n",
    "def prepare_prophet_data_pure(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Pure Logic: Rename columns for Prophet.\"\"\"\n",
    "    df = data.reset_index()\n",
    "    if 'Date' in df.columns:\n",
    "        df['ds'] = df['Date'].dt.tz_localize(None)\n",
    "    else:\n",
    "        df['ds'] = df.index.tz_localize(None)\n",
    "        \n",
    "    if 'Close' in df.columns:\n",
    "        df['y'] = df['Close']\n",
    "    elif df.shape[1] > 0:\n",
    "        df['y'] = df.iloc[:, 0]\n",
    "        \n",
    "    return df[['ds', 'y']]\n",
    "\n",
    "def format_prophet_output(forecast: pd.DataFrame, ticker: str) -> str:\n",
    "    \"\"\"Pure transformation of Prophet results to text with a table.\"\"\"\n",
    "    future_data = forecast.tail(30)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "    latest_pred = forecast.iloc[-1]['yhat']\n",
    "    trend = \"UP\" if latest_pred > forecast.iloc[0]['yhat'] else \"DOWN\"\n",
    "    \n",
    "    future_data.columns = ['Date', 'Target', 'Low', 'High']\n",
    "    \n",
    "    # Weekly snapshots\n",
    "    display_df = future_data.iloc[::5].copy()\n",
    "    display_df['Date'] = display_df['Date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    table_str = display_df.to_string(index=False, float_format=\"%.2f\")\n",
    "\n",
    "    return (f\"ML Analysis for {ticker}\\n\"\n",
    "            f\"Trend: {trend}\\n\"\n",
    "            f\"--- FORECAST TABLE (Next 30 Days) ---\\n\"\n",
    "            f\"```text\\n{table_str}\\n```\") # <--- WRAPPED IN CODE BLOCK\n",
    "\n",
    "def format_search_results_pure(response: dict) -> str:\n",
    "    \"\"\"Pure Logic: Convert structured API JSON into report.\"\"\"\n",
    "    if \"error\" in response and response[\"error\"]:\n",
    "        return f\"Search Error: {response['error']}\"\n",
    "    \n",
    "    results = response.get(\"results\", [])\n",
    "    if not results:\n",
    "        return \"No relevant news found.\"\n",
    "    \n",
    "    formatted = [\"### Market Research Summary\"]\n",
    "    for item in results:\n",
    "        title = item.get(\"title\", \"Untitled\")\n",
    "        source = item.get(\"source_domain\", \"Unknown Source\")\n",
    "        url = item.get(\"url\", \"#\")\n",
    "        content = item.get(\"content\", \"\")[:500]\n",
    "        formatted.append(f\"- **{title}** ({source})\\n  *\\\"{content}...\\\"*\\n  [Link]({url})\")\n",
    "        \n",
    "    return \"\\n\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def brownianModel(TICKER: str):\n",
    "    \"\"\"\n",
    "    Uses an Effect System to model stock prediction.\n",
    "    \"\"\"\n",
    "    # TRUE MONADIC PIPELINE (The \"Winning\" Architecture)\n",
    "    # 1. Fetch Data (IO) -> 2. Calculate Params (Pure) -> 3. Simulate (IO) -> 4. Format (Pure)\n",
    "    \n",
    "    program = (\n",
    "        fetch_stock_history_io(TICKER)\n",
    "        .map(calculate_brownian_params_pure)\n",
    "        .flat_map(lambda params: \n",
    "            # We nest this lambda so we can \"capture\" the 'params' variable \n",
    "            # and use it in the final formatting step.\n",
    "            run_monte_carlo_io(params).map(\n",
    "                lambda sim_df: format_brownian_output_pure(sim_df, TICKER, params)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The ONLY place execution happens:\n",
    "    result = program.attempt().unsafe_run()\n",
    "    \n",
    "    if isinstance(result, Exception):\n",
    "        return f\"Brownian Model Failed: {str(result)}\"\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def mlModel(ticker: str):\n",
    "    \"\"\" \n",
    "    Uses an Effect System to model Facebook Prophet predictions.\n",
    "    \"\"\"\n",
    "    program = (\n",
    "        fetch_stock_history_io(ticker)\n",
    "        .map(prepare_prophet_data_pure)\n",
    "        .flat_map(lambda df: prophet_predict_io(df))\n",
    "        .map(lambda forecast: format_prophet_output(forecast, ticker))\n",
    "    )\n",
    "\n",
    "    result = program.attempt().unsafe_run()\n",
    "    \n",
    "    if isinstance(result, Exception):\n",
    "        return f\"ML Model Failed: {str(result)}\"\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def valyu_search_tool(query: str):\n",
    "    \"\"\"\n",
    "    Effectful search wrapper with Relevance Filtering.\n",
    "    \"\"\"\n",
    "    # Pipeline: Fetch Dict (IO) -> Format String (Pure)\n",
    "    program = (\n",
    "        valyu_search_io(query)\n",
    "        .map(format_search_results_pure)\n",
    "    )\n",
    "    \n",
    "    # Execution\n",
    "    return program.attempt().unsafe_run()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_prompt = (\n",
    "    \"You are a Quantitative Analyst. Use the provided ML and Statistical tools to analyze the stock ticker provided. \"\n",
    "    \"ONLY ENTER THE ABBREVIATION OF THE STOCK TO THE TOOLS. \"\n",
    "    \"Your report must be detailed and data-heavy. You MUST include:\\n\"\n",
    "    \"1. The exact current price of the stock.\\n\"\n",
    "    \"2. The specific daily price targets for the next 30 days from the models.\\n\"\n",
    "    \"3. The median prediction and confidence intervals from the Brownian motion model.\\n\"\n",
    "    \"4. A clear statement of the trend direction (UP/DOWN/FLAT) based on the math.\\n\"\n",
    "    \"5. If a tool fails, explicitly state why (e.g., 'Not enough data').\"\n",
    ")\n",
    "trend_agent = create_agent(model, system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": trend_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ), tools=[mlModel, brownianModel])\n",
    "\n",
    "noise_prompt = (\n",
    "    \"You are a Market Researcher. Use the search tool to find recent news, sentiment, and macro factors affecting the stock. \"\n",
    "    \"Do not just summarize; provide a detailed list of findings. You MUST include:\\n\"\n",
    "    \"1. Specific headlines, dates, and sources of the news you found.\\n\"\n",
    "    \"2. Direct quotes or key statistics from the search results.\\n\"\n",
    "    \"3. Any upcoming events (earnings dates, product launches).\\n\"\n",
    "    \"4. The overall market sentiment supported by specific evidence.\"\n",
    ")\n",
    "noise_agent = create_agent(model, [valyu_search_tool], system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": noise_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = trend_agent.invoke({\"messages\": [HumanMessage(\"analyze AMZN stock\")]})\n",
    "\n",
    "#ai_message = result[\"messages\"][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Trend AgentExecuting Noise Agent\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:48:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:48:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: can you make predictions on Amazon stock?\n",
      "\n",
      "Classifications:\n",
      "  quant: AMZN\n",
      "  research: AMZN news and sentiment\n",
      "\n",
      "============================================================\n",
      "\n",
      "Final Answer:\n",
      "Due Diligence Report: Amazon (AMZN) Stock Prediction Analysis  \n",
      "Date: 2026-02-07\n",
      "\n",
      "1. Executive Summary\n",
      "\n",
      "Based on current quantitative forecasts and technical trend analysis, I recommend a **Hold** stance on Amazon (AMZN). While our models point to a continued upward trajectory in the stock price—with a robust positive drift and credible volatility—widening confidence intervals and some recent data anomalies warrant caution for new deployments of significant capital. For long-term investors, maintaining or moderately accumulating existing positions is justified, but “buy on the dip” strategies may be prudent for new entrants given forecast uncertainty and sector-wide volatility.\n",
      "\n",
      "2. Methodology & Technical Deep-Dive\n",
      "\n",
      "**Stochastic Process Used:**  \n",
      "The primary engine of our predictive framework is a Geometric Brownian Motion (GBM) model. This is a continuous-time stochastic process typically used in quantitative finance to capture both the unpredictable (random) and expected (trending) motion of stock prices, governed by two key parameters: drift (μ) and volatility (σ).\n",
      "\n",
      "**Key Technical Parameters:**\n",
      "\n",
      "- **Annualized Volatility (σ):** 31.53%  \n",
      "  - This measures the standard deviation of AMZN’s returns, annualized. It reflects the scale of price swings expected over a year.\n",
      "- **Annualized Drift (μ):** 15.52%  \n",
      "  - This is the expected log-return per year, i.e., the average directional \"pull\" of the stock, upward here.\n",
      "- The model simulates thousands of possible future price paths, then summarizes the likely outcome as a median (most representative outcome) and 90% confidence intervals (CI)—the range within which the price is likely to land 90% of the time.\n",
      "\n",
      "**Mathematical Foundation:**  \n",
      "Price at time t:  \n",
      "\\( S_t = S_0 \\cdot \\exp((\\mu - 0.5\\sigma^2)t + \\sigma W_t) \\)  \n",
      "Where \\( W_t \\) is a standard Brownian motion (random component).\n",
      "\n",
      "- The drift (μ) pushes returns upward over time.\n",
      "- The volatility (σ) determines the width of the area where the price might wander.\n",
      "\n",
      "**Machine Learning Model (ML Model):**  \n",
      "Supplementary targets are also produced via an ML regression approach for day-by-day forecasts. Note that current ML output is anomalously scaled (due to either a data transformation error or unprocessed split adjustment), but its **trend direction and increments** remain consistent and were incorporated into the high-level directional call.\n",
      "\n",
      "3. Quantitative Analysis (The Numbers)\n",
      "\n",
      "**Exact Current Price of AMZN (Brownian Model):**\n",
      "\n",
      "- The Brownian Model estimates the current price at approximately $210.32.\n",
      "\n",
      "**Daily Price Targets for the Next 30 Days (ML Model - Excerpt):**\n",
      "\n",
      "```\n",
      "| Date          | Target          | Low           | High          |\n",
      "|---------------|----------------|---------------|---------------|\n",
      "| 2026-02-07    | 1,770,118,572.26 | 1,770,118,443.08 | 1,770,118,706.05 |\n",
      "| 2026-02-12    | 1,770,854,573.99 | 1,770,854,437.74 | 1,770,854,697.58 |\n",
      "| 2026-02-17    | 1,771,286,697.67 | 1,771,286,569.10 | 1,771,286,831.24 |\n",
      "| 2026-02-22    | 1,771,414,921.35 | 1,771,414,779.39 | 1,771,415,068.96 |\n",
      "| 2026-02-27    | 1,772,150,951.27 | 1,772,150,781.00 | 1,772,151,100.99 |\n",
      "| 2026-03-04    | 1,772,583,046.37 | 1,772,582,866.55 | 1,772,583,224.03 |\n",
      "```\n",
      "\n",
      "**Brownian Motion Model: Median Prediction and Confidence Intervals**\n",
      "\n",
      "```\n",
      "- Technical parameters: Annualized Volatility = 31.53%, Annualized Drift = 15.52%\n",
      "- Weekly forecasts with 90% confidence intervals:\n",
      "  - 2026-02-09: $210.32 (no interval, as this is \"now\")\n",
      "  - 2026-02-16: Median $211.37, CI [$196.27, $228.20]\n",
      "  - 2026-02-23: Median $211.88, CI [$191.37, $232.33]\n",
      "  - 2026-03-02: Median $212.69, CI [$186.83, $240.19]\n",
      "  - 2026-03-09: Median $213.86, CI [$185.19, $246.53]\n",
      "  - 2026-03-16: Median $214.51, CI [$181.75, $251.81]\n",
      "  - 2026-03-23: Median $215.35, CI [$179.28, $254.66]\n",
      "```\n",
      "\n",
      "4. Market Context (The News)\n",
      "\n",
      "**Recent News and Market Sentiment (June 2024–February 2026):**\n",
      "\n",
      "- *Amazon Stock Hits New High After Strong Q1 Earnings* (Source: CNBC, June 2024): Surging on revenue beats.\n",
      "- *Amazon Expands AI Offerings Amid Tech Rally* (Reuters, June 2024): Announcements of further cloud/AI service penetration.\n",
      "- Management highlighted ongoing investments in logistics, AWS, and generative AI tools, signaling a diversified revenue base.\n",
      "- Analyst community: Upgrades from major banks (e.g., “Morgan Stanley upgrades Amazon to Overweight, target $220”)—indicating constructive forward-looking sentiment.\n",
      "- Macro factors: Tech sector benefiting from soft-landing expectations and resilient consumer demand; however, regulatory headwinds in antitrust and labor may constrain upside.\n",
      "- *Upcoming Events*: Awaiting next earnings, potential product launches (such as new AI-driven Echo devices), and Amazon Prime Day could further boost top line.\n",
      "\n",
      "Sources: CNBC, Reuters, Morgan Stanley, Yahoo Finance, Amazon Investor Relations.  \n",
      "(NOTE: Please cross-reference for latest headlines as timely access may vary.)\n",
      "\n",
      "5. Risk Factors & Conclusion\n",
      "\n",
      "- **Volatility:** With an annualized volatility of 31.53%, AMZN’s price can swing significantly in either direction over short intervals, meaning the downside risk is material—especially into uncertain macro or regulatory events.\n",
      "- **Forecast Uncertainty:** The widening confidence intervals (CI: e.g., $185–$254 by late March) underscore growing prediction risk with time.\n",
      "- **Data/Model Limitation:** ML model’s anomalously high numerical outputs suggest technical issues; thus, forecast reliance is reserved for direction/increment only, not precise price targeting.\n",
      "- **Market/Regulatory Risks:** Antitrust lawsuits, labor organizing, and global e-commerce deceleration could all impact fundamental valuations despite current optimism.\n",
      "- **Macro Sensitivity:** Sector-wide sell-offs or higher interest rates may quickly compress elevated multiples in megacap tech stocks.\n",
      "\n",
      "**Conclusion:**  \n",
      "The probabilistic math supports a gradual upward trajectory for AMZN, courtesy of a strong drift (15.52%) and resilient cloud/AI business momentum. Still, the high volatility and broadening confidence bands mean “Hold” is the most prudent call: maintain exposure, accumulate on weakness, but avoid aggressive short-term speculation until after the next round of earnings and major product/news catalysts.\n",
      "\n",
      "*End of Report*\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class ClassificationResult(BaseModel):  \n",
    "    \"\"\"Result of classifying a user query into agent-specific sub-questions.\"\"\"\n",
    "    classifications: list[Classification] = Field(\n",
    "        description=\"List of agents to invoke with their targeted sub-questions\"\n",
    "    )\n",
    "\n",
    "def classify_query(state: RouterState) -> dict:\n",
    "    \"\"\"Classify query and spawn agents for BOTH quant and research.\"\"\"\n",
    "    structured_llm = model.with_structured_output(ClassificationResult)  \n",
    "\n",
    "    # FIX: The system prompt now explicitly instructs to create TWO tasks\n",
    "    system_prompt = \"\"\"You are a Supervisor Agent. \n",
    "    When the user asks for a stock prediction, you MUST generate TWO separate instructions:\n",
    "    \n",
    "    1. One for the 'quant' agent to run the mathematical models (Brownian & Prophet).\n",
    "    2. One for the 'research' agent to find news and sentiment.\n",
    "    \n",
    "    OUTPUT format:\n",
    "    Return a list of TWO classifications.\n",
    "    - Classification 1: source='quant', query='[Ticker Symbol]' (e.g., 'AMZN')\n",
    "    - Classification 2: source='research', query='[Ticker Symbol] news and sentiment'\n",
    "    \"\"\"\n",
    "\n",
    "    result = structured_llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": state[\"query\"]}\n",
    "    ])\n",
    "\n",
    "    return {\"classifications\": result.classifications}\n",
    "\n",
    "def route_to_agents(state: RouterState) -> list[Send]:\n",
    "    \"\"\"Fan out to agents based on classifications.\"\"\"\n",
    "    return [\n",
    "        Send(c[\"source\"], {\"query\": c[\"query\"]})  \n",
    "        for c in state[\"classifications\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "def run_trend_agent(state: RouterState):\n",
    "    \"\"\"Invokes the Quant Agent\"\"\"\n",
    "    print(\"Executing Trend Agent\")\n",
    "    response = trend_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": state[\"query\"]}]})\n",
    "    \n",
    "    return {\"results\": [{\"source\": \"quant\", \"result\": response[\"messages\"][-1].content}]}\n",
    "\n",
    "def run_noise_agent(state: RouterState):\n",
    "    \"\"\"Invokes the Research Agent\"\"\"\n",
    "    print(\"Executing Noise Agent\")\n",
    "    response = noise_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": state[\"query\"]}]})\n",
    "    \n",
    "    return {\"results\": [{\"source\": \"research\", \"result\": response[\"messages\"][-1].content}]}\n",
    "\n",
    "def synthesize_results(state: RouterState) -> dict:\n",
    "    \"\"\"Combine results from all agents into a comprehensive report.\"\"\"\n",
    "    if not state[\"results\"]:\n",
    "        return {\"final_answer\": \"No results found from any knowledge source.\"}\n",
    "\n",
    "    formatted = [\n",
    "        f\"--- REPORT FROM {r['source'].upper()} DEPARTMENT ---\\n{r['result']}\\n------------------------------------------------\"\n",
    "        for r in state[\"results\"]\n",
    "    ]\n",
    "\n",
    "    # UPDATE: Prompt now specifically demands TABLE PRESERVATION\n",
    "    synthesis_prompt = f\"\"\"You are a Senior Investment Analyst compiling a comprehensive Due Diligence Report.\n",
    "    The user asked: \"{state['query']}\"\n",
    "\n",
    "    Your goal is to provide a \"White Box\" analysis—explaining NOT just the prediction, but HOW the math worked.\n",
    "\n",
    "    STRICTLY FOLLOW THIS REPORT STRUCTURE:\n",
    "\n",
    "    1. **Executive Summary**\n",
    "       - A high-level verdict (Buy/Sell/Hold/Wait).\n",
    "\n",
    "    2. **Methodology & Technical Deep-Dive**\n",
    "       - Explain the logic behind the models.\n",
    "       - **Brownian Motion:** State the \"Annualized Volatility\" and \"Drift\".\n",
    "    \n",
    "    3. **Quantitative Analysis (The Numbers)**\n",
    "       - **CRITICAL:** The tools provided DATA TABLES (text spreadsheets) wrapped in code blocks.\n",
    "       - You **MUST COPY THESE TABLES EXACTLY** into your report. \n",
    "       - **DO NOT** convert the tables into bullet points. \n",
    "       - **DO NOT** summarize the table data.\n",
    "       - Just copy the Markdown code blocks containing the tables.\n",
    "\n",
    "    4. **Market Context (The News)**\n",
    "       - Summarize the news headlines and sentiment.\n",
    "       - CITE SOURCES.\n",
    "\n",
    "    5. **Risk Factors & Conclusion**\n",
    "       - Specific risks (e.g., \"High volatility of X% increases downside risk\").\n",
    "\n",
    "    Do not shorten the content. USE THE TECHNICAL PARAMETERS (Sigma, Mu, CI) PROVIDED IN THE TEXT.\"\"\"\n",
    "\n",
    "    synthesis_response = model.invoke([\n",
    "        {\"role\": \"system\", \"content\": synthesis_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"\\n\\n\".join(formatted)}\n",
    "    ])\n",
    "\n",
    "    return {\"final_answer\": synthesis_response.content}\n",
    "\n",
    "workflow = (\n",
    "    StateGraph(RouterState)\n",
    "    .add_node(\"classify\", classify_query)\n",
    "    .add_node(\"quant\", run_trend_agent)\n",
    "    .add_node(\"research\", run_noise_agent)\n",
    "    .add_node(\"synthesize\", synthesize_results)\n",
    "    \n",
    "    # Start at classify\n",
    "    .add_edge(START, \"classify\")\n",
    "    \n",
    "    # Fan out to both agents based on the list returned by classify_query\n",
    "    .add_conditional_edges(\"classify\", route_to_agents, [\"quant\", \"research\"])\n",
    "    \n",
    "    # Both agents pipe their output to synthesize\n",
    "    .add_edge(\"quant\", \"synthesize\")\n",
    "    .add_edge(\"research\", \"synthesize\")\n",
    "    \n",
    "    # End after synthesis\n",
    "    .add_edge(\"synthesize\", END)\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "\n",
    "result = workflow.invoke({\n",
    "    \"query\": \"can you make predictions on Amazon stock?\"\n",
    "})\n",
    "\n",
    "print(\"Original query:\", result[\"query\"])\n",
    "print(\"\\nClassifications:\")\n",
    "for c in result[\"classifications\"]:\n",
    "    print(f\"  {c['source']}: {c['query']}\")\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "print(\"Final Answer:\")\n",
    "print(result[\"final_answer\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
