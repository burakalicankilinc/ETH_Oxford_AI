{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reinstall all langchain packages to the latest matching versions\n",
    "#%pip install -U --force-reinstall langchain langchain-community langchain-core langchain-google-genai valyu prophet yfinance matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burakalicankilinc/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Annotated, Literal, TypedDict, List\n",
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "# --- LIBRARIES ---\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from pydantic import BaseModel, Field\n",
    "from valyu import Valyu \n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentInput(TypedDict):\n",
    "    \"\"\"Simple input state for each subagent.\"\"\"\n",
    "    query: str\n",
    "\n",
    "\n",
    "class AgentOutput(TypedDict):\n",
    "    \"\"\"Output from each subagent.\"\"\"\n",
    "    source: str\n",
    "    result: str\n",
    "\n",
    "\n",
    "class Classification(TypedDict):\n",
    "    \"\"\"A single routing decision: which agent to call with what query.\"\"\"\n",
    "    source: Literal[\"quant\", \"research\"]\n",
    "    query: str\n",
    "\n",
    "\n",
    "class RouterState(TypedDict):\n",
    "    query: str\n",
    "    classifications: list[Classification]\n",
    "    results: Annotated[list[AgentOutput], operator.add]  \n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool \n",
    "def brownianModel(TICKER: str):\n",
    "    \"\"\" \n",
    "    Uses geometric brownian motion and monte carlo method to predict stock prices 30 days ahead.\n",
    "    Returns technical parameters (Drift, Volatility) and a 90% Confidence Interval.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # main variables\n",
    "        scen_size = 1000 \n",
    "        HISTORICAL_YEARS = 2\n",
    "        PREDICTION_DAYS = 30\n",
    "        stock_name = TICKER\n",
    "\n",
    "        end_date = pd.Timestamp.today().normalize()\n",
    "        start_date = end_date - pd.DateOffset(years=HISTORICAL_YEARS)\n",
    "        pred_end_date = end_date + pd.tseries.offsets.BDay(PREDICTION_DAYS)\n",
    "\n",
    "        # Download and prepare data\n",
    "        prices = yf.download(tickers=stock_name, start=start_date, end=pred_end_date, progress=False)\n",
    "        \n",
    "        if prices.empty:\n",
    "            return f\"Error: No data found for {stock_name}\"\n",
    "\n",
    "        # Handle yfinance MultiIndex\n",
    "        if isinstance(prices.columns, pd.MultiIndex):\n",
    "            prices = prices['Close']\n",
    "            if isinstance(prices, pd.DataFrame) and stock_name in prices.columns:\n",
    "                 prices = prices[stock_name]\n",
    "        elif 'Close' in prices.columns:\n",
    "            prices = prices['Close']\n",
    "        \n",
    "        if isinstance(prices, pd.DataFrame):\n",
    "             prices = prices.iloc[:, 0]\n",
    "\n",
    "        future_dates = pd.bdate_range(start=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "                        end=pd.to_datetime(pred_end_date))\n",
    "\n",
    "        train_set = prices.loc[:end_date]\n",
    "        \n",
    "        if len(train_set) < 2:\n",
    "            return \"Error: Not enough historical data for prediction.\"\n",
    "\n",
    "        daily_returns = ((train_set / train_set.shift(1)) - 1).dropna()\n",
    "        So = train_set.iloc[-1]\n",
    "        \n",
    "        # --- ENRICHED METADATA CALCULATION ---\n",
    "        mu = np.mean(daily_returns)\n",
    "        sigma = np.std(daily_returns)\n",
    "        \n",
    "        # Annualize for reporting\n",
    "        annual_drift = mu * 252\n",
    "        annual_vol = sigma * np.sqrt(252)\n",
    "        \n",
    "        if np.isnan(sigma) or sigma == 0:\n",
    "            return \"Error: Volatility calculation failed.\"\n",
    "\n",
    "        # Simulation\n",
    "        T_days = len(future_dates)\n",
    "        N = T_days\n",
    "        t = np.arange(1, N + 1)\n",
    "\n",
    "        # Vectorized Monte Carlo\n",
    "        b = {str(scen): np.random.normal(0, 1, N) for scen in range(1, scen_size + 1)}\n",
    "        W = {str(scen): b[str(scen)].cumsum() for scen in range(1, scen_size + 1)}\n",
    "\n",
    "        drift = (mu - 0.5 * sigma ** 2) * t\n",
    "        diffusion = {str(scen): sigma * W[str(scen)] for scen in range(1, scen_size + 1)}\n",
    "\n",
    "        S = np.array([So * np.exp(drift + diffusion[str(scen)]) for scen in range(1, scen_size + 1)])\n",
    "        \n",
    "        # Stats: Mean, 5th percentile (Bear), 95th percentile (Bull)\n",
    "        S_pred = np.mean(S, axis=0)\n",
    "        S_low = np.percentile(S, 5, axis=0)\n",
    "        S_high = np.percentile(S, 95, axis=0)\n",
    "\n",
    "        final_df = pd.DataFrame({\n",
    "            'mean': S_pred,\n",
    "            'low': S_low,\n",
    "            'high': S_high\n",
    "        }, index=future_dates[:len(S_pred)])\n",
    "\n",
    "        # Create detailed output string\n",
    "        rows = []\n",
    "        for date, row in final_df.iterrows():\n",
    "            rows.append(f\"{date.date()}: Mean ${row['mean']:.2f} (Range: ${row['low']:.2f} - ${row['high']:.2f})\")\n",
    "            \n",
    "        daily_data = '\\n'.join(rows)\n",
    "\n",
    "        # RETURN THE \"HOW\" DATA\n",
    "        return (f\"Brownian Motion Analysis for {stock_name}:\\n\"\n",
    "                f\"--- TECHNICAL PARAMETERS ---\\n\"\n",
    "                f\"Historical Data Points: {len(train_set)}\\n\"\n",
    "                f\"Annualized Volatility (Sigma): {annual_vol:.2%}\\n\"\n",
    "                f\"Annualized Drift (Mu): {annual_drift:.2%}\\n\"\n",
    "                f\"Simulations Run: {scen_size}\\n\"\n",
    "                f\"Confidence Interval: 90% (5th to 95th percentile)\\n\"\n",
    "                f\"----------------------------\\n\"\n",
    "                f\"Forecast Data:\\n{daily_data}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Brownian Model failed: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def mlModel(ticker: str):\n",
    "    \"\"\" \n",
    "    Uses Facebook Prophet to predict stock prices 30 days ahead.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = yf.Ticker(ticker).history(period=\"2y\")\n",
    "        if data.empty:\n",
    "            return \"Error: No data found\"\n",
    "        \n",
    "        df = data.reset_index()\n",
    "        df['ds'] = df['Date'].dt.tz_localize(None)\n",
    "        df['y'] = df['Close']\n",
    "\n",
    "        m = Prophet(daily_seasonality=True)\n",
    "        m.fit(df)\n",
    "\n",
    "        future = m.make_future_dataframe(periods=30)\n",
    "        forecast = m.predict(future)\n",
    "\n",
    "        # Plot logic (omitted for brevity, keep your original plot logic here if needed)\n",
    "        graph_filename = f\"{ticker}_forecast.png\"\n",
    "        # ... (keep plot saving code if you want) ...\n",
    "\n",
    "        future_data = forecast.tail(30)\n",
    "        latest_pred = forecast.iloc[-1]['yhat']\n",
    "        current_price = df.iloc[-1]['y']\n",
    "        trend = \"UP\" if latest_pred > current_price else \"DOWN\"\n",
    "        \n",
    "        # ENRICHED OUTPUT\n",
    "        return (f\"Machine Learning (Prophet) Analysis for {ticker}\\n\"\n",
    "                f\"--- MODEL DETAILS ---\\n\"\n",
    "                f\"Algorithm: Additive Regression Model (Prophet)\\n\"\n",
    "                f\"Training Data: {len(df)} days\\n\"\n",
    "                f\"Seasonality: Daily/Weekly enabled\\n\"\n",
    "                f\"Trend Detected: {trend}\\n\"\n",
    "                f\"---------------------\\n\"\n",
    "                f\"Daily Price Targets (Next 30 Days):\\n\"\n",
    "                f\"{future_data[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(30).to_string()}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Prediction failed: {e}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def valyu_search_tool(query: str):\n",
    "    \"\"\"\n",
    "    Searches the web using Valyu API to get specific market news and context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # FIX: Instantiate the client first!\n",
    "        # This creates the 'self' context the error is asking for.\n",
    "        client = Valyu(api_key=os.environ.get(\"VALYU_API_KEY\"))\n",
    "        \n",
    "        # Now call .answer() on the instance 'client', not the class 'Valyu'\n",
    "        response = client.answer(query)\n",
    "        \n",
    "        # Robustly handle different response types\n",
    "        if isinstance(response, dict) and 'contents' in response:\n",
    "            return str(response['contents'])\n",
    "        elif hasattr(response, 'contents'):\n",
    "            return str(response.contents)\n",
    "        else:\n",
    "            return str(response)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Search failed: {str(e)}\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_prompt = (\n",
    "    \"You are a Quantitative Analyst. Use the provided ML and Statistical tools to analyze the stock ticker provided. \"\n",
    "    \"ONLY ENTER THE ABBREVIATION OF THE STOCK TO THE TOOLS. \"\n",
    "    \"Your report must be detailed and data-heavy. You MUST include:\\n\"\n",
    "    \"1. The exact current price of the stock.\\n\"\n",
    "    \"2. The specific daily price targets for the next 30 days from the models.\\n\"\n",
    "    \"3. The median prediction and confidence intervals from the Brownian motion model.\\n\"\n",
    "    \"4. A clear statement of the trend direction (UP/DOWN/FLAT) based on the math.\\n\"\n",
    "    \"5. If a tool fails, explicitly state why (e.g., 'Not enough data').\"\n",
    ")\n",
    "trend_agent = create_agent(model, system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": trend_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ), tools=[mlModel, brownianModel])\n",
    "\n",
    "noise_prompt = (\n",
    "    \"You are a Market Researcher. Use the search tool to find recent news, sentiment, and macro factors affecting the stock. \"\n",
    "    \"Do not just summarize; provide a detailed list of findings. You MUST include:\\n\"\n",
    "    \"1. Specific headlines, dates, and sources of the news you found.\\n\"\n",
    "    \"2. Direct quotes or key statistics from the search results.\\n\"\n",
    "    \"3. Any upcoming events (earnings dates, product launches).\\n\"\n",
    "    \"4. The overall market sentiment supported by specific evidence.\"\n",
    ")\n",
    "noise_agent = create_agent(model, [valyu_search_tool], system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": noise_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = trend_agent.invoke({\"messages\": [HumanMessage(\"analyze AMZN stock\")]})\n",
    "\n",
    "#ai_message = result[\"messages\"][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
