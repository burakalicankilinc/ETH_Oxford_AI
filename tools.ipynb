{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.2.9-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-1.2.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-4.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting valyu\n",
      "  Using cached valyu-2.5.4-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting prophet\n",
      "  Using cached prophet-1.3.0-py3-none-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Collecting yfinance\n",
      "  Using cached yfinance-1.1.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (52 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (79 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.7 (from langchain)\n",
      "  Using cached langgraph-1.0.8-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
      "  Using cached langsmith-0.6.9-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting packaging>=23.2.0 (from langchain-core)\n",
      "  Using cached packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
      "  Downloading tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core)\n",
      "  Using cached uuid_utils-0.14.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (4.9 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached langgraph_sdk-0.3.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached ormsgpack-1.12.2-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (3.2 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached orjson-3.11.7-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Using cached langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Using cached sqlalchemy-2.0.46-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Using cached numpy-2.4.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Using cached langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-genai<2.0.0,>=1.56.0 (from langchain-google-genai)\n",
      "  Using cached google_genai-1.62.0-py3-none-any.whl.metadata (53 kB)\n",
      "Collecting google-auth<3.0.0,>=2.47.0 (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting distro<2,>=1.7.0 (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cryptography>=38.0.3 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached cryptography-46.0.4-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Using cached pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting openai>=1.66.0 (from valyu)\n",
      "  Using cached openai-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anthropic>=0.46.0 (from valyu)\n",
      "  Using cached anthropic-0.78.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet)\n",
      "  Using cached cmdstanpy-1.3.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting holidays<1,>=0.25 (from prophet)\n",
      "  Using cached holidays-0.90-py3-none-any.whl.metadata (50 kB)\n",
      "Collecting tqdm>=4.36.1 (from prophet)\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting importlib_resources (from prophet)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting python-dateutil<3,>=2.9.0.post0 (from holidays<1,>=0.25->prophet)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3,>=2.9.0.post0->holidays<1,>=0.25->prophet)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Using cached multitasking-0.0.12-py3-none-any.whl\n",
      "Collecting platformdirs>=2.0.0 (from yfinance)\n",
      "  Using cached platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pytz>=2022.5 (from yfinance)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Using cached frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Using cached peewee-3.19.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting curl_cffi<0.14,>=0.7 (from yfinance)\n",
      "  Using cached curl_cffi-0.13.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Using cached protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting cffi>=1.12.0 (from curl_cffi<0.14,>=0.7->yfinance)\n",
      "  Using cached cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.61.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-12.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting docstring-parser<1,>=0.15 (from anthropic>=0.46.0->valyu)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic>=0.46.0->valyu)\n",
      "  Using cached jiter-0.13.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Using cached soupsieve-2.8.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pycparser (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance)\n",
      "  Using cached pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting stanio<2.0.0,>=0.4.0 (from cmdstanpy>=1.0.4->prophet)\n",
      "  Using cached stanio-0.5.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached langchain-1.2.9-py3-none-any.whl (111 kB)\n",
      "Using cached langchain_core-1.2.9-py3-none-any.whl (496 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langgraph-1.0.8-py3-none-any.whl (158 kB)\n",
      "Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
      "Using cached langgraph_sdk-0.3.4-py3-none-any.whl (67 kB)\n",
      "Using cached langsmith-0.6.9-py3-none-any.whl (319 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached uuid_utils-0.14.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (601 kB)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl (490 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached sqlalchemy-2.0.46-cp313-cp313-macosx_11_0_arm64.whl (2.2 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Using cached langchain_google_genai-4.2.0-py3-none-any.whl (66 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached google_genai-1.62.0-py3-none-any.whl (724 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached google_auth-2.48.0-py3-none-any.whl (236 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached valyu-2.5.4-py3-none-any.whl (41 kB)\n",
      "Using cached prophet-1.3.0-py3-none-macosx_11_0_arm64.whl (12.1 MB)\n",
      "Using cached holidays-0.90-py3-none-any.whl (1.4 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached yfinance-1.1.0-py2.py3-none-any.whl (129 kB)\n",
      "Using cached curl_cffi-0.13.0-cp39-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached matplotlib-3.10.8-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Using cached pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl (9.9 MB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anthropic-0.78.0-py3-none-any.whl (405 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached jiter-0.13.0-cp313-cp313-macosx_11_0_arm64.whl (317 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl (181 kB)\n",
      "Using cached cmdstanpy-1.3.0-py3-none-any.whl (99 kB)\n",
      "Using cached stanio-0.5.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (274 kB)\n",
      "Using cached cryptography-46.0.4-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.1-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\n",
      "Using cached frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.4.2-cp313-cp313-macosx_14_0_arm64.whl (5.2 MB)\n",
      "Using cached openai-2.17.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached orjson-3.11.7-cp313-cp313-macosx_15_0_arm64.whl (125 kB)\n",
      "Using cached ormsgpack-1.12.2-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (378 kB)\n",
      "Using cached packaging-26.0-py3-none-any.whl (74 kB)\n",
      "Using cached peewee-3.19.0-py3-none-any.whl (411 kB)\n",
      "Using cached pillow-12.1.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
      "Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Using cached pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached soupsieve-2.8.3-py3-none-any.whl (37 kB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached pycparser-3.0-py3-none-any.whl (48 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: pytz, peewee, multitasking, filetype, zstandard, xxhash, websockets, uuid-utils, urllib3, typing-extensions, tqdm, tenacity, soupsieve, sniffio, six, pyyaml, python-dotenv, pyparsing, pycparser, pyasn1, protobuf, propcache, platformdirs, pillow, packaging, ormsgpack, orjson, numpy, mypy-extensions, multidict, kiwisolver, jsonpointer, jiter, importlib_resources, idna, httpx-sse, h11, frozenlist, frozendict, fonttools, docstring-parser, distro, cycler, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, stanio, SQLAlchemy, rsa, requests, python-dateutil, pydantic-core, pyasn1-modules, marshmallow, jsonpatch, httpcore, contourpy, cffi, beautifulsoup4, anyio, aiosignal, requests-toolbelt, pydantic, pandas, matplotlib, httpx, holidays, dataclasses-json, curl_cffi, cryptography, aiohttp, yfinance, pydantic-settings, openai, langsmith, langgraph-sdk, google-auth, cmdstanpy, anthropic, valyu, prophet, langchain-core, langgraph-checkpoint, langchain-text-splitters, google-genai, langgraph-prebuilt, langchain-google-genai, langchain-classic, langgraph, langchain-community, langchain\n",
      "\u001b[2K  Attempting uninstall: pytz\n",
      "\u001b[2K    Found existing installation: pytz 2025.2\n",
      "\u001b[2K    Uninstalling pytz-2025.2:\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2\n",
      "\u001b[2K  Attempting uninstall: peewee\n",
      "\u001b[2K    Found existing installation: peewee 3.19.0\n",
      "\u001b[2K    Uninstalling peewee-3.19.0:\n",
      "\u001b[2K      Successfully uninstalled peewee-3.19.0━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: multitasking━━━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Found existing installation: multitasking 0.0.122m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Uninstalling multitasking-0.0.12:━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K      Successfully uninstalled multitasking-0.0.12[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: filetype━━━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Found existing installation: filetype 1.2.0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Uninstalling filetype-1.2.0:━━━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K      Successfully uninstalled filetype-1.2.0[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: zstandard━━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Found existing installation: zstandard 0.25.0\u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Uninstalling zstandard-0.25.0:━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K      Successfully uninstalled zstandard-0.25.0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: xxhash━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Found existing installation: xxhash 3.6.0[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Uninstalling xxhash-3.6.0:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K      Successfully uninstalled xxhash-3.6.0━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: websockets━━━━━━━━━━\u001b[0m \u001b[32m 1/96\u001b[0m [peewee]\n",
      "\u001b[2K    Found existing installation: websockets 15.0.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling websockets-15.0.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled websockets-15.0.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K  Attempting uninstall: uuid-utils━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: uuid_utils 0.14.0━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling uuid_utils-0.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled uuid_utils-0.14.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: urllib3 2.6.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling urllib3-2.6.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.6.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/96\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━━━━━\u001b[0m \u001b[32m 9/96\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/96\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/96\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/96\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/96\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tenacity━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]tensions]\n",
      "\u001b[2K    Found existing installation: tenacity 9.1.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling tenacity-9.1.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled tenacity-9.1.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K  Attempting uninstall: soupsieve━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K    Found existing installation: soupsieve 2.8.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling soupsieve-2.8.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled soupsieve-2.8.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K  Attempting uninstall: sniffio━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K    Found existing installation: sniffio 1.3.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling sniffio-1.3.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled sniffio-1.3.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K  Attempting uninstall: six━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling six-1.17.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/96\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: pyyaml━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: python-dotenv━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: python-dotenv 1.2.1━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling python-dotenv-1.2.1:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled python-dotenv-1.2.1━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: pyparsing━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: pyparsing 3.3.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling pyparsing-3.3.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled pyparsing-3.3.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/96\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: pycparserm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: pycparser 3.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling pycparser-3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled pycparser-3.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: pyasn1━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: pyasn1 0.6.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling pyasn1-0.6.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled pyasn1-0.6.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: protobuf━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling protobuf-6.33.5:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/96\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: propcache0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: propcache 0.4.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling propcache-0.4.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled propcache-0.4.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: platformdirs━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: platformdirs 4.5.1━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling platformdirs-4.5.1:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled platformdirs-4.5.1━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: pillowm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: pillow 12.1.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling pillow-12.1.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled pillow-12.1.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/96\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: packaging90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: packaging 26.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-26.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-26.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: ormsgpack━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: ormsgpack 1.12.2━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling ormsgpack-1.12.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled ormsgpack-1.12.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: orjson0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: orjson 3.11.7━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling orjson-3.11.7:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled orjson-3.11.7━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: numpy90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: numpy 2.4.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/96\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling numpy-2.4.2:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/96\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.4.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/96\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: mypy-extensions━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/96\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: mypy_extensions 1.1.0━━━━━━━━\u001b[0m \u001b[32m27/96\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling mypy_extensions-1.1.0:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/96\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled mypy_extensions-1.1.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K  Attempting uninstall: multidictm━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Found existing installation: multidict 6.7.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Uninstalling multidict-6.7.1:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K      Successfully uninstalled multidict-6.7.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K  Attempting uninstall: kiwisolver━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Found existing installation: kiwisolver 1.4.9━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Uninstalling kiwisolver-1.4.9:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K      Successfully uninstalled kiwisolver-1.4.9━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K  Attempting uninstall: jsonpointer━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Found existing installation: jsonpointer 3.0.0━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Uninstalling jsonpointer-3.0.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/96\u001b[0m [mypy-extensions]\n",
      "\u001b[2K      Successfully uninstalled jsonpointer-3.0.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K  Attempting uninstall: jiterm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Found existing installation: jiter 0.13.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Uninstalling jiter-0.13.0:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K      Successfully uninstalled jiter-0.13.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K  Attempting uninstall: importlib_resources━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Found existing installation: importlib_resources 6.5.2━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Uninstalling importlib_resources-6.5.2:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K      Successfully uninstalled importlib_resources-6.5.2━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K  Attempting uninstall: idna0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Found existing installation: idna 3.11━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Uninstalling idna-3.11:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K      Successfully uninstalled idna-3.11━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/96\u001b[0m [jsonpointer]\n",
      "\u001b[2K  Attempting uninstall: httpx-sse[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]er]\n",
      "\u001b[2K    Found existing installation: httpx-sse 0.4.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling httpx-sse-0.4.3:[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled httpx-sse-0.4.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: h11╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: h11 0.16.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling h11-0.16.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled h11-0.16.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: frozenlist90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: frozenlist 1.8.0━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling frozenlist-1.8.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled frozenlist-1.8.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: frozendict90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: frozendict 2.4.7━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling frozendict-2.4.7:90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled frozendict-2.4.7━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: fonttools[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: fonttools 4.61.1━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling fonttools-4.61.1:90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled fonttools-4.61.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/96\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: docstring-parser90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/96\u001b[0m [fonttools]\n",
      "\u001b[2K    Found existing installation: docstring_parser 0.17.0━━━━━━\u001b[0m \u001b[32m39/96\u001b[0m [fonttools]\n",
      "\u001b[2K    Uninstalling docstring_parser-0.17.0:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/96\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled docstring_parser-0.17.0━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: distro\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: distro 1.9.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling distro-1.9.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled distro-1.9.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: cycler\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: cycler 0.12.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling cycler-0.12.1:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled cycler-0.12.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.4━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.4:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.4━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: certifi[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: certifi 2026.1.4━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling certifi-2026.1.4:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled certifi-2026.1.4━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: attrs╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: attrs 25.4.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling attrs-25.4.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled attrs-25.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: annotated-types━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: annotated-types 0.7.0━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling annotated-types-0.7.0:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled annotated-types-0.7.0━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: aiohappyeyeballs━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: aiohappyeyeballs 2.6.1━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling aiohappyeyeballs-2.6.1:━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled aiohappyeyeballs-2.6.1━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: yarlm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/96\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: yarl 1.22.090m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]-parser]\n",
      "\u001b[2K    Uninstalling yarl-1.22.0:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K      Successfully uninstalled yarl-1.22.0m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K  Attempting uninstall: typing-inspection0m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.2━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.2:0m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.2━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K  Attempting uninstall: typing-inspect\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K    Found existing installation: typing-inspect 0.9.0━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K    Uninstalling typing-inspect-0.9.0:\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/96\u001b[0m [yarl]\n",
      "\u001b[2K      Successfully uninstalled typing-inspect-0.9.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/96\u001b[0m [typing-inspect]\n",
      "\u001b[2K  Attempting uninstall: stanio91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/96\u001b[0m [typing-inspect]\n",
      "\u001b[2K    Found existing installation: stanio 0.5.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/96\u001b[0m [typing-inspect]\n",
      "\u001b[2K    Uninstalling stanio-0.5.1:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/96\u001b[0m [stanio]ect]\n",
      "\u001b[2K      Successfully uninstalled stanio-0.5.1m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/96\u001b[0m [stanio]\n",
      "\u001b[2K  Attempting uninstall: SQLAlchemy╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/96\u001b[0m [stanio]\n",
      "\u001b[2K    Found existing installation: SQLAlchemy 2.0.46━━━━━━━━━━━━\u001b[0m \u001b[32m51/96\u001b[0m [stanio]\n",
      "\u001b[2K    Uninstalling SQLAlchemy-2.0.46:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/96\u001b[0m [stanio]\n",
      "\u001b[2K      Successfully uninstalled SQLAlchemy-2.0.46━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/96\u001b[0m [stanio]\n",
      "\u001b[2K  Attempting uninstall: rsa━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Found existing installation: rsa 4.9.10m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Uninstalling rsa-4.9.1:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K      Successfully uninstalled rsa-4.9.1[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K  Attempting uninstall: requests1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.41.5━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.41.5:m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.41.5━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K  Attempting uninstall: pyasn1-modulesm\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Found existing installation: pyasn1_modules 0.4.2━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Uninstalling pyasn1_modules-0.4.2:m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K      Successfully uninstalled pyasn1_modules-0.4.2━━━━━━━━━━━\u001b[0m \u001b[32m52/96\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K  Attempting uninstall: marshmallow\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/96\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Found existing installation: marshmallow 3.26.2━━━━━━━━━━━\u001b[0m \u001b[32m57/96\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Uninstalling marshmallow-3.26.2:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/96\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K      Successfully uninstalled marshmallow-3.26.2━━━━━━━━━━━━━\u001b[0m \u001b[32m57/96\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K  Attempting uninstall: jsonpatch91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/96\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Found existing installation: jsonpatch 1.33━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/96\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Uninstalling jsonpatch-1.33:[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/96\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K      Successfully uninstalled jsonpatch-1.33m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]]\n",
      "\u001b[2K  Attempting uninstall: httpcore\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Found existing installation: httpcore 1.0.9━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Uninstalling httpcore-1.0.9:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K      Successfully uninstalled httpcore-1.0.90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K  Attempting uninstall: contourpy[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Found existing installation: contourpy 1.3.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Uninstalling contourpy-1.3.3:[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K      Successfully uninstalled contourpy-1.3.3m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K  Attempting uninstall: cffi\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Found existing installation: cffi 2.0.0[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Uninstalling cffi-2.0.0:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/96\u001b[0m [jsonpatch]\n",
      "\u001b[2K      Successfully uninstalled cffi-2.0.0m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/96\u001b[0m [cffi]]\n",
      "\u001b[2K  Attempting uninstall: beautifulsoup4╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/96\u001b[0m [cffi]\n",
      "\u001b[2K    Found existing installation: beautifulsoup4 4.14.3━━━━━━━━\u001b[0m \u001b[32m62/96\u001b[0m [cffi]\n",
      "\u001b[2K    Uninstalling beautifulsoup4-4.14.3:\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/96\u001b[0m [cffi]\n",
      "\u001b[2K      Successfully uninstalled beautifulsoup4-4.14.3━━━━━━━━━━\u001b[0m \u001b[32m62/96\u001b[0m [cffi]\n",
      "\u001b[2K  Attempting uninstall: anyio\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/96\u001b[0m [cffi]\n",
      "\u001b[2K    Found existing installation: anyio 4.12.190m━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/96\u001b[0m [cffi]\n",
      "\u001b[2K    Uninstalling anyio-4.12.1:━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K      Successfully uninstalled anyio-4.12.1m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K  Attempting uninstall: aiosignalm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K    Found existing installation: aiosignal 1.4.0m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K    Uninstalling aiosignal-1.4.0:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K      Successfully uninstalled aiosignal-1.4.090m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K  Attempting uninstall: requests-toolbelt[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K    Found existing installation: requests-toolbelt 1.0.0━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K    Uninstalling requests-toolbelt-1.0.0:[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K      Successfully uninstalled requests-toolbelt-1.0.0━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K  Attempting uninstall: pydantic0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K    Found existing installation: pydantic 2.12.5m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K    Uninstalling pydantic-2.12.5:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.12.590m━━━━━━━━━━━━━\u001b[0m \u001b[32m64/96\u001b[0m [anyio]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m67/96\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: pandas 3.0.0\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m67/96\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling pandas-3.0.0:━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m67/96\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled pandas-3.0.00m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m67/96\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m68/96\u001b[0m [pandas]^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Force reinstall all langchain packages to the latest matching versions\n",
    "%pip install -U --force-reinstall langchain langchain-community langchain-core langchain-google-genai valyu prophet yfinance matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Annotated, Literal, TypedDict, List\n",
    "\n",
    "# --- LIBRARIES ---\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from pydantic import BaseModel, Field\n",
    "from valyu import Valyu \n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=1.0,  \n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def mlModel(ticker: str):\n",
    "    \"\"\" \n",
    "    Uses Facebook Prophet to predict stock prices 30 days ahead.\n",
    "    Returns daily price targets and saves a plot to a .png file.\n",
    "    the png files name is generated by graph_filename = f\"{ticker}_forecast.png\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # search stock data\n",
    "\n",
    "        data = yf.Ticker(ticker).history(period=\"2y\")\n",
    "        if data.empty:\n",
    "            return \"Error: No data found\"\n",
    "        \n",
    "        # Format for prophet\n",
    "        \n",
    "        df = data.reset_index()\n",
    "        df['ds'] = df['Date'].dt.tz_localize(None)\n",
    "        df['y'] = df['Close']\n",
    "\n",
    "        # Train\n",
    "\n",
    "        m = Prophet(daily_seasonality=True)\n",
    "        m.fit(df)\n",
    "\n",
    "        # Predict\n",
    "\n",
    "        future = m.make_future_dataframe(periods=30)\n",
    "        forecast = m.predict(future)\n",
    "\n",
    "        # Save the Graph\n",
    "\n",
    "        fig1 = m.plot(forecast)\n",
    "        plt.title(f\"{ticker} 30-Day Forecast\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "\n",
    "        graph_filename = f\"{ticker}_forecast.png\"\n",
    "        plt.savefig(graph_filename)\n",
    "        plt.close()\n",
    "\n",
    "        # List 30 day prediction\n",
    "        future_data = forecast.tail(30)\n",
    "\n",
    "        daily_tracking = []\n",
    "        for index, row in future_data.iterrows():\n",
    "            date_str = row['ds'].strftime('%Y-%m-%d')\n",
    "            price_str = f\"${row['yhat']:.2f}\"\n",
    "            daily_tracking.append(f\"{date_str}: {price_str}\")\n",
    "\n",
    "        daily_summary = \"\\n\".join(daily_tracking)\n",
    "\n",
    "        latest_pred = forecast.iloc[-1]['yhat']\n",
    "        current_price = df.iloc[-1]['y']\n",
    "        trend = \"UP\" if latest_pred > current_price else \"DOWN\"\n",
    "        print(trend)\n",
    "        \n",
    "        # Return Everything\n",
    "        return (f\"Analysis Complete for {ticker}\\n\"\n",
    "                f\"Graph saved to: {graph_filename}\\n\"\n",
    "                f\"Trend: {trend}\\n\\n\"\n",
    "                f\"Daily Price Targets (Next 30 Days):\\n\"\n",
    "                f\"{daily_summary}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Prediction failed: {e}\"\n",
    "    \n",
    "\n",
    "@tool \n",
    "def brownianModel(TICKER: str):\n",
    "    \"\"\" \n",
    "    Uses geometric brownian motion and monte carlo method to predict stock prices 30 days ahead, for a given ticker. \n",
    "    Returns daily price predictions 30 trading days ahead, with a historical lookback period of 24 months.\n",
    "    This can only be used if the stock has at least a two-year old history. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # main variables\n",
    "        scen_size = 1000 # Reduced for speed, increase if needed\n",
    "        HISTORICAL_YEARS = 2\n",
    "        PREDICTION_DAYS = 30\n",
    "        stock_name = TICKER\n",
    "\n",
    "        end_date = pd.Timestamp.today().normalize()\n",
    "        start_date = end_date - pd.DateOffset(years=HISTORICAL_YEARS)\n",
    "        pred_end_date = end_date + pd.tseries.offsets.BDay(PREDICTION_DAYS)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Download and prepare data\n",
    "        # -----------------------------\n",
    "        # Fix for yfinance returning multi-index\n",
    "        prices = yf.download(tickers=stock_name, start=start_date, end=pred_end_date, progress=False)\n",
    "        \n",
    "        if prices.empty:\n",
    "            return f\"Error: No data found for {stock_name}\"\n",
    "\n",
    "        # Handle yfinance MultiIndex (recent API change)\n",
    "        if isinstance(prices.columns, pd.MultiIndex):\n",
    "            prices = prices['Close']\n",
    "            # If still a dataframe (multiple tickers?), select the specific ticker\n",
    "            if isinstance(prices, pd.DataFrame) and stock_name in prices.columns:\n",
    "                 prices = prices[stock_name]\n",
    "        elif 'Close' in prices.columns:\n",
    "            prices = prices['Close']\n",
    "        \n",
    "        # Ensure we have a Series, not a DataFrame\n",
    "        if isinstance(prices, pd.DataFrame):\n",
    "             prices = prices.iloc[:, 0]\n",
    "\n",
    "        # Generate business days (weekdays only)\n",
    "        future_dates = pd.bdate_range(start=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "                        end=pd.to_datetime(pred_end_date))\n",
    "\n",
    "        train_set = prices.loc[:end_date]\n",
    "        \n",
    "        if len(train_set) < 2:\n",
    "            return \"Error: Not enough historical data for prediction.\"\n",
    "\n",
    "        daily_returns = ((train_set / train_set.shift(1)) - 1).dropna()\n",
    "\n",
    "        So = train_set.iloc[-1]\n",
    "        dt = 1  # day\n",
    "        \n",
    "        # Calculate volatility and drift\n",
    "        mu = np.mean(daily_returns)\n",
    "        sigma = np.std(daily_returns)\n",
    "        \n",
    "        # If sigma is 0 or NaN, we can't predict\n",
    "        if np.isnan(sigma) or sigma == 0:\n",
    "            return \"Error: Volatility calculation failed (sigma is 0 or NaN).\"\n",
    "\n",
    "        # Simulation\n",
    "        T_days = len(future_dates)\n",
    "        N = T_days\n",
    "        t = np.arange(1, N + 1)\n",
    "\n",
    "        b = {str(scen): np.random.normal(0, 1, N) for scen in range(1, scen_size + 1)}\n",
    "        W = {str(scen): b[str(scen)].cumsum() for scen in range(1, scen_size + 1)}\n",
    "\n",
    "        drift = (mu - 0.5 * sigma ** 2) * t\n",
    "        diffusion = {str(scen): sigma * W[str(scen)] for scen in range(1, scen_size + 1)}\n",
    "\n",
    "        S = np.array([So * np.exp(drift + diffusion[str(scen)]) for scen in range(1, scen_size + 1)])\n",
    "        \n",
    "        # Average prediction\n",
    "        S_pred = np.mean(S, axis=0)\n",
    "\n",
    "        final_df = pd.DataFrame({\n",
    "            'pred': S_pred\n",
    "        }, index=future_dates[:len(S_pred)])\n",
    "\n",
    "        # Create output string\n",
    "        rows = [f\"{date.date()}: ${price:.2f}\" for date, price in zip(final_df.index, final_df['pred'])]\n",
    "        result = '\\n'.join(rows)\n",
    "        print(result)\n",
    "\n",
    "        if not result:\n",
    "            return \"Error: Model ran but produced no output rows.\"\n",
    "\n",
    "        return f\"Brownian Motion Forecast for {stock_name}:\\n{result}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # This prevents the 'ValueError: contents are required' crash\n",
    "        return f\"Brownian Model failed: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool \n",
    "#query_general is the prompt given to Valyu, and it should be on general / industry specific news/articles instead of stoc specific.\n",
    "#max_results refers to the number of sources that should be returned by the function. (Top N)\n",
    "def generalInfo(query_general: str) -> str:\n",
    "    \"\"\"\n",
    "    query_general: the query that is to be sent to the ai, to find information regarding the news and researches focused on the macroeconomy and broad industry-specific news and researches relating to the stock. The top 10 relevant information will be recorded. \n",
    "    news within the most recent 12 months will be considered.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the API key from environment\n",
    "    API_KEY = os.environ.get(\"VALYU_API_KEY\")\n",
    "    # Initialize the Valyu client\n",
    "    valyu = Valyu(api_key=API_KEY)\n",
    "\n",
    "    # ---------- NEWS SEARCH ----------\n",
    "    news_response = valyu.search(\n",
    "        query=query_general,\n",
    "        search_type=\"news\",\n",
    "        max_num_results=10,\n",
    "        relevance_threshold=0.7,\n",
    "        max_price=0.0, #free content only\n",
    "        start_date=datetime.now().date() - timedelta(days=365),\n",
    "        end_date=datetime.now().date(),\n",
    "        excluded_sources=[\"reddit.com\", \"twitter.com\", \"x.com\"],\n",
    "        response_length=\"medium\",\n",
    "        fast_mode=False,\n",
    "    )\n",
    "\n",
    "    # ---------- PROPRIETARY SEARCH ----------\n",
    "    proprietary_response = valyu.search(\n",
    "        query=query_general,\n",
    "        search_type=\"proprietary\",\n",
    "        max_num_results=10,\n",
    "        relevance_threshold=0.7,\n",
    "        max_price=0.0,\n",
    "        start_date=datetime.now().date() - timedelta(days=365),\n",
    "        end_date=datetime.now().date(),\n",
    "        response_length=\"medium\",\n",
    "        fast_mode=False,\n",
    "    )\n",
    "\n",
    "    # Combine results safely\n",
    "    response = (\n",
    "        (news_response.get(\"results\") or []) +\n",
    "        (proprietary_response.get(\"results\") or [])\n",
    "    )\n",
    "\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    for result in response.get('results', []):\n",
    "        results_list.append({\n",
    "            \"title\": result.get('title', 'No title'),\n",
    "            \"url\": result.get('url', 'No URL'),\n",
    "            \"snippet\": result.get('snippet') or result.get('content', 'No snippet')\n",
    "        })\n",
    "\n",
    "    #Turns result_list (a dictioanry) into a readable string.\n",
    "\n",
    "    lines = []\n",
    "    for r in enumerate(results_list, 1):\n",
    "        lines.append(\n",
    "            f\"TITLE: {r['title']}\\n\"\n",
    "            f\"URL: {r['url']}\\n\"\n",
    "            f\"Summary: {r['snippet']}\\n\"\n",
    "        )\n",
    "    response_str = \"\\n\".join(lines)\n",
    "    return str(response_str)\n",
    "\n",
    "\n",
    "\n",
    "@tool \n",
    "def specificInfo(query_specific: str) -> str:\n",
    "    \"\"\"\n",
    "    the input will be labelled query_general, which is the query that is to be sent to the ai, to find information regarding the news and researches focused on data referring to the specific stock in question. The top 10 relevant information will be recorded. \n",
    "    news within the most recent 12 months will be considered.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the API key from environment\n",
    "    API_KEY = os.environ.get(\"VALYU_API_KEY\")\n",
    "    # Initialize the Valyu client\n",
    "    valyu = Valyu(api_key=API_KEY)\n",
    "\n",
    "    # ---------- NEWS SEARCH ----------\n",
    "    news_response = valyu.search(\n",
    "        query=query_specific,\n",
    "        search_type=\"news\",\n",
    "        max_num_results=10,\n",
    "        relevance_threshold=0.7,\n",
    "        max_price=0.0, #free content only\n",
    "        start_date=datetime.now().date() - timedelta(days=365),\n",
    "        end_date=datetime.now().date(),\n",
    "        excluded_sources=[\"reddit.com\", \"twitter.com\", \"x.com\"],\n",
    "        response_length=\"medium\",\n",
    "        fast_mode=False,\n",
    "    )\n",
    "\n",
    "    # ---------- PROPRIETARY SEARCH ----------\n",
    "    proprietary_response = valyu.search(\n",
    "        query=query_specific,\n",
    "        search_type=\"proprietary\",\n",
    "        max_num_results=10,\n",
    "        relevance_threshold=0.7,\n",
    "        max_price=0.0,\n",
    "        start_date=datetime.now().date() - timedelta(days=365),\n",
    "        end_date=datetime.now().date(),\n",
    "        response_length=\"medium\",\n",
    "        fast_mode=False,\n",
    "    )\n",
    "\n",
    "    # Combine results safely\n",
    "    response = (\n",
    "        (news_response.get(\"results\") or []) +\n",
    "        (proprietary_response.get(\"results\") or [])\n",
    "    )\n",
    "\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    for result in response.get('results', []):\n",
    "        results_list.append({\n",
    "            \"title\": result.get('title', 'No title'),\n",
    "            \"url\": result.get('url', 'No URL'),\n",
    "            \"snippet\": result.get('snippet') or result.get('content', 'No snippet')\n",
    "        })\n",
    "\n",
    "    #Turns result_list (a dictioanry) into a readable string.\n",
    "\n",
    "    lines = []\n",
    "    for r in enumerate(results_list, 1):\n",
    "        lines.append(\n",
    "            f\"TITLE: {r['title']}\\n\"\n",
    "            f\"URL: {r['url']}\\n\"\n",
    "            f\"Summary: {r['snippet']}\\n\"\n",
    "        )\n",
    "    response_str = \"\\n\".join(lines)\n",
    "    return str(response_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_prompt = \"You are a Quantitative Analyst. Use the provided ML and Statistical tools to analyze the stock ticker provided. ONLY ENTER THE ABBREVIATION OF THE STOCK TO THE TOOLS. Summarize the technical outlook.\"\n",
    "trend_agent = create_agent(model, system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": trend_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ), tools=[mlModel, brownianModel])\n",
    "\n",
    "noise_prompt = \"You are a Market Researcher. Use the search tool to find recent news, sentiment, and macro factors affecting the stock.\"\n",
    "noise_agent = create_agent(model, [valyu_search_tool], system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": noise_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trend_agent.invoke({\"messages\": [HumanMessage(\"analyze AMZN stock\")]})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    results: Annotated[List[str], operator.add] \n",
    "\n",
    "def run_trend_agent(state: AgentState):\n",
    "    \"\"\"Invokes the Quant Agent\"\"\"\n",
    "    print(\"Executing Trend Agent\")\n",
    "    response = trend_agent.invoke({\"messages\": HumanMessage(f\"Analyze {state['query']}\")})\n",
    "    return {\"results\": [f\"QUANT ANALYSIS:\\n{response['output']}\"]}\n",
    "\n",
    "def run_noise_agent(state: AgentState):\n",
    "    \"\"\"Invokes the Research Agent\"\"\"\n",
    "    print(\"Executing Noise Agent\")\n",
    "    response = noise_agent.invoke({\"messages\": HumanMessage(f\"Find news for {state['query']}\")})\n",
    "    return {\"results\": [f\"RESEARCH ANALYSIS:\\n{response['output']}\"]}\n",
    "\n",
    "def aggregator(state: AgentState):\n",
    "    \"\"\"Combines results into a final answer\"\"\"\n",
    "    print(\"Aggregating Results\")\n",
    "    final_prompt = (\n",
    "        f\"Combine the following reports into a comprehensive investment memo for {state['query']}:\\n\\n\"\n",
    "        + \"\\n\\n\".join(state[\"results\"])\n",
    "    )\n",
    "    response = model.invoke({\"messages\" : HumanMessage(final_prompt)})\n",
    "    print(f\"\\nFINAL ANSWER:\\n{response.content}\")\n",
    "    return {\"results\": [response.content]}\n",
    "\n",
    "class RouteSchema(BaseModel):\n",
    "    targets: List[Literal[\"quant\", \"research\"]] = Field(\n",
    "        description=\"Which agents to hire? Quant for numbers/charts, Research for news/sentiment.\"\n",
    "    )\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"trend_node\", run_trend_agent)\n",
    "workflow.add_node(\"noise_node\", run_noise_agent)\n",
    "workflow.add_node(\"aggregator\", aggregator)\n",
    "\n",
    "\n",
    "def route_query(state: AgentState) -> List[Send]:\n",
    "    structured_llm = model.with_structured_output(RouteSchema)\n",
    "    decision = structured_llm.invoke(f\"Analyze: {state['query']}\")\n",
    "    \n",
    "    routes = []\n",
    "    if \"quant\" in decision.targets:\n",
    "        routes.append(Send(\"trend_node\", state))\n",
    "    if \"research\" in decision.targets:\n",
    "        routes.append(Send(\"noise_node\", state))\n",
    "    if not routes:\n",
    "        routes = [Send(\"trend_node\", state), Send(\"noise_node\", state)]\n",
    "        \n",
    "    return routes\n",
    "\n",
    "workflow.add_conditional_edges(START, route_query)\n",
    "workflow.add_edge(\"trend_node\", \"aggregator\")\n",
    "workflow.add_edge(\"noise_node\", \"aggregator\")\n",
    "workflow.add_edge(\"aggregator\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"What is the outlook for AAPL stock?\"\n",
    "    inputs = {\"query\": HumanMessage(user_query), \"results\": []}\n",
    "\n",
    "    for output in app.stream(inputs):\n",
    "        pass \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
