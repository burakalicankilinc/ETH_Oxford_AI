{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reinstall all langchain packages to the latest matching versions\n",
    "#%pip install -U --force-reinstall langchain langchain-community langchain-core langchain-google-genai valyu prophet yfinance matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Annotated, Literal, TypedDict, List\n",
    "\n",
    "# --- LIBRARIES ---\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from pydantic import BaseModel, Field\n",
    "from valyu import Valyu \n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=1.0,  \n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def mlModel(ticker: str):\n",
    "    \"\"\" \n",
    "    Uses Facebook Prophet to predict stock prices 30 days ahead.\n",
    "    Returns daily price targets and saves a plot to a .png file.\n",
    "    the png files name is generated by graph_filename = f\"{ticker}_forecast.png\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # search stock data\n",
    "\n",
    "        data = yf.Ticker(ticker).history(period=\"2y\")\n",
    "        if data.empty:\n",
    "            return \"Error: No data found\"\n",
    "        \n",
    "        # Format for prophet\n",
    "        \n",
    "        df = data.reset_index()\n",
    "        df['ds'] = df['Date'].dt.tz_localize(None)\n",
    "        df['y'] = df['Close']\n",
    "\n",
    "        # Train\n",
    "\n",
    "        m = Prophet(daily_seasonality=True)\n",
    "        m.fit(df)\n",
    "\n",
    "        # Predict\n",
    "\n",
    "        future = m.make_future_dataframe(periods=30)\n",
    "        forecast = m.predict(future)\n",
    "\n",
    "        # Save the Graph\n",
    "\n",
    "        fig1 = m.plot(forecast)\n",
    "        plt.title(f\"{ticker} 30-Day Forecast\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "\n",
    "        graph_filename = f\"{ticker}_forecast.png\"\n",
    "        plt.savefig(graph_filename)\n",
    "        plt.close()\n",
    "\n",
    "        # List 30 day prediction\n",
    "        future_data = forecast.tail(30)\n",
    "\n",
    "        daily_tracking = []\n",
    "        for index, row in future_data.iterrows():\n",
    "            date_str = row['ds'].strftime('%Y-%m-%d')\n",
    "            price_str = f\"${row['yhat']:.2f}\"\n",
    "            daily_tracking.append(f\"{date_str}: {price_str}\")\n",
    "\n",
    "        daily_summary = \"\\n\".join(daily_tracking)\n",
    "\n",
    "        latest_pred = forecast.iloc[-1]['yhat']\n",
    "        current_price = df.iloc[-1]['y']\n",
    "        trend = \"UP\" if latest_pred > current_price else \"DOWN\"\n",
    "        print(trend)\n",
    "        \n",
    "        # Return Everything\n",
    "        return (f\"Analysis Complete for {ticker}\\n\"\n",
    "                f\"Graph saved to: {graph_filename}\\n\"\n",
    "                f\"Trend: {trend}\\n\\n\"\n",
    "                f\"Daily Price Targets (Next 30 Days):\\n\"\n",
    "                f\"{daily_summary}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Prediction failed: {e}\"\n",
    "    \n",
    "\n",
    "@tool \n",
    "def brownianModel(TICKER: str):\n",
    "    \"\"\" \n",
    "    Uses geometric brownian motion and monte carlo method to predict stock prices 30 days ahead, for a given ticker. \n",
    "    Returns daily price predictions 30 trading days ahead, with a historical lookback period of 24 months.\n",
    "    This can only be used if the stock has at least a two-year old history. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # main variables\n",
    "        scen_size = 1000 # Reduced for speed, increase if needed\n",
    "        HISTORICAL_YEARS = 2\n",
    "        PREDICTION_DAYS = 30\n",
    "        stock_name = TICKER\n",
    "\n",
    "        end_date = pd.Timestamp.today().normalize()\n",
    "        start_date = end_date - pd.DateOffset(years=HISTORICAL_YEARS)\n",
    "        pred_end_date = end_date + pd.tseries.offsets.BDay(PREDICTION_DAYS)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Download and prepare data\n",
    "        # -----------------------------\n",
    "        # Fix for yfinance returning multi-index\n",
    "        prices = yf.download(tickers=stock_name, start=start_date, end=pred_end_date, progress=False)\n",
    "        \n",
    "        if prices.empty:\n",
    "            return f\"Error: No data found for {stock_name}\"\n",
    "\n",
    "        # Handle yfinance MultiIndex (recent API change)\n",
    "        if isinstance(prices.columns, pd.MultiIndex):\n",
    "            prices = prices['Close']\n",
    "            # If still a dataframe (multiple tickers?), select the specific ticker\n",
    "            if isinstance(prices, pd.DataFrame) and stock_name in prices.columns:\n",
    "                 prices = prices[stock_name]\n",
    "        elif 'Close' in prices.columns:\n",
    "            prices = prices['Close']\n",
    "        \n",
    "        # Ensure we have a Series, not a DataFrame\n",
    "        if isinstance(prices, pd.DataFrame):\n",
    "             prices = prices.iloc[:, 0]\n",
    "\n",
    "        # Generate business days (weekdays only)\n",
    "        future_dates = pd.bdate_range(start=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "                        end=pd.to_datetime(pred_end_date))\n",
    "\n",
    "        train_set = prices.loc[:end_date]\n",
    "        \n",
    "        if len(train_set) < 2:\n",
    "            return \"Error: Not enough historical data for prediction.\"\n",
    "\n",
    "        daily_returns = ((train_set / train_set.shift(1)) - 1).dropna()\n",
    "\n",
    "        So = train_set.iloc[-1]\n",
    "        dt = 1  # day\n",
    "        \n",
    "        # Calculate volatility and drift\n",
    "        mu = np.mean(daily_returns)\n",
    "        sigma = np.std(daily_returns)\n",
    "        \n",
    "        # If sigma is 0 or NaN, we can't predict\n",
    "        if np.isnan(sigma) or sigma == 0:\n",
    "            return \"Error: Volatility calculation failed (sigma is 0 or NaN).\"\n",
    "\n",
    "        # Simulation\n",
    "        T_days = len(future_dates)\n",
    "        N = T_days\n",
    "        t = np.arange(1, N + 1)\n",
    "\n",
    "        b = {str(scen): np.random.normal(0, 1, N) for scen in range(1, scen_size + 1)}\n",
    "        W = {str(scen): b[str(scen)].cumsum() for scen in range(1, scen_size + 1)}\n",
    "\n",
    "        drift = (mu - 0.5 * sigma ** 2) * t\n",
    "        diffusion = {str(scen): sigma * W[str(scen)] for scen in range(1, scen_size + 1)}\n",
    "\n",
    "        S = np.array([So * np.exp(drift + diffusion[str(scen)]) for scen in range(1, scen_size + 1)])\n",
    "        \n",
    "        # Average prediction\n",
    "        S_pred = np.mean(S, axis=0)\n",
    "\n",
    "        final_df = pd.DataFrame({\n",
    "            'pred': S_pred\n",
    "        }, index=future_dates[:len(S_pred)])\n",
    "\n",
    "        # Create output string\n",
    "        rows = [f\"{date.date()}: ${price:.2f}\" for date, price in zip(final_df.index, final_df['pred'])]\n",
    "        result = '\\n'.join(rows)\n",
    "        print(result)\n",
    "\n",
    "        if not result:\n",
    "            return \"Error: Model ran but produced no output rows.\"\n",
    "\n",
    "        return f\"Brownian Motion Forecast for {stock_name}:\\n{result}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # This prevents the 'ValueError: contents are required' crash\n",
    "        return f\"Brownian Model failed: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def valyu_search_tool(query: str):\n",
    "    \"\"\"\n",
    "    Searches the web using Valyu API to get specific market news and context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using the .answer method from your provided code\n",
    "        response = Valyu.answer(query)\n",
    "        \n",
    "        # Extract content safely\n",
    "        if hasattr(response, 'contents'):\n",
    "            return response.contents\n",
    "        elif isinstance(response, dict) and 'contents' in response:\n",
    "            return response['contents']\n",
    "        else:\n",
    "            return str(response)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Search failed: {e}\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_prompt = \"You are a Quantitative Analyst. Use the provided ML and Statistical tools to analyze the stock ticker provided. ONLY ENTER THE ABBREVIATION OF THE STOCK TO THE TOOLS. Summarize the technical outlook.\"\n",
    "trend_agent = create_agent(model, system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": trend_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ), tools=[mlModel, brownianModel])\n",
    "\n",
    "noise_prompt = \"You are a Market Researcher. Use the search tool to find recent news, sentiment, and macro factors affecting the stock.\"\n",
    "noise_agent = create_agent(model, [valyu_search_tool], system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": noise_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-09: $210.50\n",
      "2026-02-10: $210.46\n",
      "2026-02-11: $210.52\n",
      "2026-02-12: $210.45\n",
      "2026-02-13: $210.45\n",
      "2026-02-16: $210.29\n",
      "2026-02-17: $210.39\n",
      "2026-02-18: $210.73\n",
      "2026-02-19: $210.81\n",
      "2026-02-20: $210.79\n",
      "2026-02-23: $211.02\n",
      "2026-02-24: $211.09\n",
      "2026-02-25: $211.12\n",
      "2026-02-26: $211.18\n",
      "2026-02-27: $211.28\n",
      "2026-03-02: $211.41\n",
      "2026-03-03: $211.42\n",
      "2026-03-04: $211.38\n",
      "2026-03-05: $211.35\n",
      "2026-03-06: $211.52\n",
      "2026-03-09: $211.52\n",
      "2026-03-10: $211.33\n",
      "2026-03-11: $211.41\n",
      "2026-03-12: $211.77\n",
      "2026-03-13: $211.97\n",
      "2026-03-16: $212.12\n",
      "2026-03-17: $212.19\n",
      "2026-03-18: $212.22\n",
      "2026-03-19: $212.43\n",
      "2026-03-20: $212.56\n",
      "{'messages': [HumanMessage(content='analyze AMZN stock', additional_kwargs={}, response_metadata={}, id='2fda7757-8e08-484d-bc8c-c9ca6d9e96f6'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'brownianModel', 'arguments': '{\"TICKER\": \"AMZN\"}'}, '__gemini_function_call_thought_signatures__': {'702937c0-8df6-47cc-b2ae-2d82b899bdc8': 'Cu4CAb4+9vsIcKMOL8PxzBHX+CiQYHTV6nDjBqYi2cLYGYjUv3ApoBO1N2Pf8yMup5DStacHZDnVtL9ETDZazW5pf6nnlmHPZKXgRfjgjJ9v8UPvGNNbX8+oEbGpepNLepmWXrW+yIeJIr9lXMNB8Wb6BkEf0C3jSsInwg0xCXVaUhapxcex1IRjQhbFKFzqkCorg9FbRhDRHBYcd7DfhgMRfgyoh8Kj4obxFDBN5qFrTM36JL7KWwyCLMJ/B7L3i8ZscLGsKbbKKLR7ea3WnhOa5VucOyTH8+Crdst+bgsvy2ZcL4Qx2F06lPXC5jQcT8ftwD7SXLybTRH36amDuJfH6U68/KFKaNVPIw8RoVz2Ij2ju49iV+0YIHZy/hqD++QuzUbUz62wumIDOWjLs2guGtdesY66cGm/AswMv/jxTzBmVliXJFzOKTE8moMyS2Bm8ryNZlVeND+01pWqtXvJ9PGlzfqbXVZrkRT8PmAK'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c37a1-a965-7301-81e1-acdde94c5026-0', tool_calls=[{'name': 'mlModel', 'args': {'ticker': 'AMZN'}, 'id': '702937c0-8df6-47cc-b2ae-2d82b899bdc8', 'type': 'tool_call'}, {'name': 'brownianModel', 'args': {'TICKER': 'AMZN'}, 'id': '7e680291-bece-4bae-b3fd-6948d170a7a4', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 235, 'output_tokens': 109, 'total_tokens': 344, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 76}}), ToolMessage(content=\"Prediction failed: name 'Prophet' is not defined\", name='mlModel', id='3c731cf2-82d8-42a3-b5f4-4d2d7dbd4e85', tool_call_id='702937c0-8df6-47cc-b2ae-2d82b899bdc8'), ToolMessage(content='Brownian Motion Forecast for AMZN:\\n2026-02-09: $210.50\\n2026-02-10: $210.46\\n2026-02-11: $210.52\\n2026-02-12: $210.45\\n2026-02-13: $210.45\\n2026-02-16: $210.29\\n2026-02-17: $210.39\\n2026-02-18: $210.73\\n2026-02-19: $210.81\\n2026-02-20: $210.79\\n2026-02-23: $211.02\\n2026-02-24: $211.09\\n2026-02-25: $211.12\\n2026-02-26: $211.18\\n2026-02-27: $211.28\\n2026-03-02: $211.41\\n2026-03-03: $211.42\\n2026-03-04: $211.38\\n2026-03-05: $211.35\\n2026-03-06: $211.52\\n2026-03-09: $211.52\\n2026-03-10: $211.33\\n2026-03-11: $211.41\\n2026-03-12: $211.77\\n2026-03-13: $211.97\\n2026-03-16: $212.12\\n2026-03-17: $212.19\\n2026-03-18: $212.22\\n2026-03-19: $212.43\\n2026-03-20: $212.56', name='brownianModel', id='994d0e0b-ec68-46c8-ad52-79955889b5a7', tool_call_id='7e680291-bece-4bae-b3fd-6948d170a7a4'), AIMessage(content=[{'type': 'text', 'text': 'The ML model encountered an error and could not provide a prediction.\\n\\nBased on the Geometric Brownian Motion and Monte Carlo method, the technical outlook for AMZN for the next 30 trading days suggests a slight upward trend. The model predicts a gradual increase in price from approximately $210.50 on February 9, 2026, to around $212.56 by March 20, 2026.', 'extras': {'signature': 'Cq4EAb4+9vuSiMJlCWsHLle6h0kAlYFaZvwg7o9kuRFwPMeirvLwxzeSC6+foDufR0y69sYF9WJR86gIpgz91nQuWYgQ0TaLbLYYjRzYbxqVHkNW1eWztbba72HgPMxJtAKLbyCHdISXMHUwzkS2/TSgY8hYTqYPlWyhy6PBibkz4z/WhbaKl0bQwF+D+W+JH6KRr4xbPLCpgvIbpV+oHinci8YDpxzsCcT02eib0tAzW4yjm+PiLHg2E2/D3o2qBd0EB9g+MVEleQ5q9hHfuz/+ISH79niyUaUwk5cevQsP8hyj93J2zok10SAsZM5mzf/D7jAsNdgO16Fa4siietXWTnbA3W4MF9DkFoRLXybAs2c4RkeisYReEVeZdR/dRQOiDgFuIA2FeM6J9Hud2rbwCIeXo88VA1cn3tn/eD6sqtIEJpiPp5aPqtFysDezzq9iZsfBi2LQIddBw3+MjhyoSjnXnRRnrnnOufwfXK1sfUiI/SJEI8r7lPgae/aQobqlwMWZXrkst1L4aB414TCYdF6TPDzB98uPV8XedJfcNOXSs/lRp71oCmlQrAF49Iu/jAWOxoKUvIyAgQBZJpHfMJBMIfsWXeVXxgLS00VPKlw6pZU6FqzOs9Vb49Avt6JayQN954AtHTbYTmNmaxtNdsrIqpdDjel9ux3RJNvdB8SJrJXiKniYW2ks1JYyN1fqX6ZVgt9XzBwsPweUG+OF4eyIfj4WCW+WAghXJ6WQ'}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c37a1-ad6b-7ab2-a690-7cca7862fa58-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 911, 'output_tokens': 238, 'total_tokens': 1149, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 144}})]}\n"
     ]
    }
   ],
   "source": [
    "result = trend_agent.invoke({\"messages\": [HumanMessage(\"analyze AMZN stock\")]})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Trend AgentExecuting Noise Agent\n",
      "\n",
      "2026-02-09: $278.26\n",
      "2026-02-10: $278.28\n",
      "2026-02-11: $278.41\n",
      "2026-02-12: $278.68\n",
      "2026-02-13: $278.95\n",
      "2026-02-16: $279.24\n",
      "2026-02-17: $279.36\n",
      "2026-02-18: $279.56\n",
      "2026-02-19: $279.67\n",
      "2026-02-20: $280.04\n",
      "2026-02-23: $280.19\n",
      "2026-02-24: $280.31\n",
      "2026-02-25: $280.53\n",
      "2026-02-26: $280.82\n",
      "2026-02-27: $281.10\n",
      "2026-03-02: $281.31\n",
      "2026-03-03: $281.43\n",
      "2026-03-04: $281.53\n",
      "2026-03-05: $281.83\n",
      "2026-03-06: $281.98\n",
      "2026-03-09: $282.55\n",
      "2026-03-10: $282.92\n",
      "2026-03-11: $283.30\n",
      "2026-03-12: $283.49\n",
      "2026-03-13: $283.94\n",
      "2026-03-16: $284.22\n",
      "2026-03-17: $284.63\n",
      "2026-03-18: $284.80\n",
      "2026-03-19: $285.06\n",
      "2026-03-20: $285.51\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     70\u001b[39m user_query = \u001b[33m\"\u001b[39m\u001b[33mWhat is the outlook for AAPL stock?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: HumanMessage(user_query), \u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m: []}\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/_runner.py:258\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tb := exc.__traceback__:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/_runner.py:520\u001b[39m, in \u001b[36m_panic_or_proceed\u001b[39m\u001b[34m(futs, timeout_exc_cls, panic)\u001b[39m\n\u001b[32m    518\u001b[39m                 interrupts.append(exc)\n\u001b[32m    519\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/_executor.py:80\u001b[39m, in \u001b[36mBackgroundExecutor.done\u001b[39m\u001b[34m(self, task)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mself\u001b[39m.tasks.pop(task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mrun_trend_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExecuting Trend Agent\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m response = trend_agent.invoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: HumanMessage(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnalyze \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m'\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)})\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQUANT ANALYSIS:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m]}\n",
      "\u001b[31mKeyError\u001b[39m: 'output'",
      "During task with name 'trend_node' and id '20d251e7-889e-e5b9-f082-29b1bbc8781d'"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    results: Annotated[List[str], operator.add] \n",
    "\n",
    "def run_trend_agent(state: AgentState):\n",
    "    \"\"\"Invokes the Quant Agent\"\"\"\n",
    "    print(\"Executing Trend Agent\")\n",
    "    response = trend_agent.invoke({\"messages\": HumanMessage(f\"Analyze {state['query']}\")})\n",
    "    return {\"results\": [f\"QUANT ANALYSIS:\\n{response['output']}\"]}\n",
    "\n",
    "def run_noise_agent(state: AgentState):\n",
    "    \"\"\"Invokes the Research Agent\"\"\"\n",
    "    print(\"Executing Noise Agent\")\n",
    "    response = noise_agent.invoke({\"messages\": HumanMessage(f\"Find news for {state['query']}\")})\n",
    "    return {\"results\": [f\"RESEARCH ANALYSIS:\\n{response['output']}\"]}\n",
    "\n",
    "def aggregator(state: AgentState):\n",
    "    \"\"\"Combines results into a final answer\"\"\"\n",
    "    print(\"Aggregating Results\")\n",
    "    final_prompt = (\n",
    "        f\"Combine the following reports into a comprehensive investment memo for {state['query']}:\\n\\n\"\n",
    "        + \"\\n\\n\".join(state[\"results\"])\n",
    "    )\n",
    "    response = model.invoke({\"messages\" : HumanMessage(final_prompt)})\n",
    "    print(f\"\\nFINAL ANSWER:\\n{response.content}\")\n",
    "    return {\"results\": [response.content]}\n",
    "\n",
    "class RouteSchema(BaseModel):\n",
    "    targets: List[Literal[\"quant\", \"research\"]] = Field(\n",
    "        description=\"Which agents to hire? Quant for numbers/charts, Research for news/sentiment.\"\n",
    "    )\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"trend_node\", run_trend_agent)\n",
    "workflow.add_node(\"noise_node\", run_noise_agent)\n",
    "workflow.add_node(\"aggregator\", aggregator)\n",
    "\n",
    "def route_query(state: AgentState) -> List[Send]:\n",
    "    structured_llm = model.with_structured_output(RouteSchema)\n",
    "    decision = structured_llm.invoke(f\"Analyze: {state['query']}\")\n",
    "    \n",
    "    routes = []\n",
    "    if \"quant\" in decision.targets:\n",
    "        routes.append(Send(\"trend_node\", state))\n",
    "    if \"research\" in decision.targets:\n",
    "        routes.append(Send(\"noise_node\", state))\n",
    "    if not routes:\n",
    "        routes = [Send(\"trend_node\", state), Send(\"noise_node\", state)]\n",
    "        \n",
    "    return routes\n",
    "\n",
    "workflow.add_conditional_edges(START, route_query)\n",
    "workflow.add_edge(\"trend_node\", \"aggregator\")\n",
    "workflow.add_edge(\"noise_node\", \"aggregator\")\n",
    "workflow.add_edge(\"aggregator\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"What is the outlook for AAPL stock?\"\n",
    "    inputs = {\"query\": HumanMessage(user_query), \"results\": []}\n",
    "\n",
    "    for output in app.stream(inputs):\n",
    "        pass \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
