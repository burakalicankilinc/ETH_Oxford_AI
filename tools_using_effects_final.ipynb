{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reinstall all langchain packages to the latest matching versions\n",
    "#%pip install -U --force-reinstall langchain langchain-community langchain-core langchain-google-genai valyu prophet yfinance matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Annotated, Literal, TypedDict, List\n",
    "from prophet import Prophet\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "from effects_core import IO\n",
    "from pure_logic import build_brownian_pipeline, build_ml_pipeline, build_search_pipeline\n",
    "\n",
    "\n",
    "# --- LIBRARIES ---\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from pydantic import BaseModel, Field\n",
    "from valyu import Valyu \n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\", model_provider=\"openai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Callable, Generic, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "U = TypeVar(\"U\")\n",
    "\n",
    "@dataclass\n",
    "class IO(Generic[T]):\n",
    "    \"\"\"\n",
    "    A pure description of a side-effectful computation.\n",
    "    Nothing runs until .unsafe_run() is called.\n",
    "    \"\"\"\n",
    "    effect: Callable[[], T]\n",
    "\n",
    "    @staticmethod\n",
    "    def pure(value: T) -> \"IO[T]\":\n",
    "        \"\"\"Lift a pure value into the IO context.\"\"\"\n",
    "        return IO(lambda: value)\n",
    "\n",
    "    @staticmethod\n",
    "    def fail(error: Exception) -> \"IO[Any]\":\n",
    "        \"\"\"Lift an error into the IO context.\"\"\"\n",
    "        def _raise(): raise error\n",
    "        return IO(_raise)\n",
    "\n",
    "    def map(self, f: Callable[[T], U]) -> \"IO[U]\":\n",
    "        \"\"\"Apply a pure function to the result of the effect.\"\"\"\n",
    "        return IO(lambda: f(self.effect()))\n",
    "\n",
    "    def flat_map(self, f: Callable[[T], \"IO[U]\"]) -> \"IO[U]\":\n",
    "        \"\"\"Chain a new effect based on the result of the previous one.\"\"\"\n",
    "        return IO(lambda: f(self.effect()).unsafe_run())\n",
    "\n",
    "    def attempt(self) -> \"IO[T | Exception]\":\n",
    "        \"\"\"Materialize errors into values (Better failure handling).\"\"\"\n",
    "        def _safe_run():\n",
    "            try:\n",
    "                return self.effect()\n",
    "            except Exception as e:\n",
    "                return e\n",
    "        return IO(_safe_run)\n",
    "\n",
    "    def unsafe_run(self) -> T:\n",
    "        \"\"\"The 'Edge' - actually executes the side effects.\"\"\"\n",
    "        return self.effect()\n",
    "\n",
    "# Helper for composing multiple IOs\n",
    "def sequence(ios: list[IO[T]]) -> IO[list[T]]:\n",
    "    def _run_all():\n",
    "        return [io.unsafe_run() for io in ios]\n",
    "    return IO(_run_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentInput(TypedDict):\n",
    "    \"\"\"Simple input state for each subagent.\"\"\"\n",
    "    query: str\n",
    "\n",
    "\n",
    "class AgentOutput(TypedDict):\n",
    "    \"\"\"Output from each subagent.\"\"\"\n",
    "    source: str\n",
    "    result: str\n",
    "\n",
    "\n",
    "class Classification(TypedDict):\n",
    "    \"\"\"A single routing decision: which agent to call with what query.\"\"\"\n",
    "    source: Literal[\"quant\", \"research\"]\n",
    "    query: str\n",
    "\n",
    "\n",
    "class RouterState(TypedDict):\n",
    "    query: str\n",
    "    classifications: list[Classification]\n",
    "    results: Annotated[list[AgentOutput], operator.add]  \n",
    "    final_answer: str\n",
    "\n",
    "class BrownianParams(TypedDict):\n",
    "    mu: float\n",
    "    sigma: float\n",
    "    last_price: float\n",
    "    annual_vol: float\n",
    "    annual_drift: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EFFECT DEFINITIONS (I/O Boundary) ---\n",
    "\n",
    "def fetch_stock_history_io(ticker: str, years: int = 2) -> IO[pd.DataFrame]:\n",
    "    \"\"\"Effect: Network Call to Yahoo Finance.\"\"\"\n",
    "    def _fetch():\n",
    "        end_date = pd.Timestamp.today().normalize()\n",
    "        start_date = end_date - pd.DateOffset(years=years)\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        # Cleanup logic (part of the fetch IO boundary)\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data = data['Close']\n",
    "            if isinstance(data, pd.DataFrame) and ticker in data.columns:\n",
    "                 data = data[ticker]\n",
    "        elif 'Close' in data.columns:\n",
    "            data = data['Close']\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "             data = data.iloc[:, 0]\n",
    "        return data\n",
    "    return IO(_fetch)\n",
    "\n",
    "def run_monte_carlo_io(params: BrownianParams, days: int = 30, scenarios: int = 1000) -> IO[pd.DataFrame]:\n",
    "    \"\"\"Effect: Random Number Generation & Simulation.\"\"\"\n",
    "    def _sim():\n",
    "        mu, sigma, S0 = params['mu'], params['sigma'], params['last_price']\n",
    "        dt = 1\n",
    "        returns = np.random.normal(loc=mu * dt, scale=sigma * np.sqrt(dt), size=(days, scenarios))\n",
    "        price_paths = np.vstack([np.full((1, scenarios), S0), S0 * np.exp(np.cumsum(returns, axis=0))])\n",
    "        return pd.DataFrame(price_paths)\n",
    "    return IO(_sim)\n",
    "\n",
    "def valyu_search_io(query: str) -> IO[str]:\n",
    "    \"\"\"Effect: External API Search (Optimized for Tokens).\"\"\"\n",
    "    def _search():\n",
    "        client = Valyu(api_key=os.environ.get(\"VALYU_API_KEY\"))\n",
    "        response = client.answer(query)\n",
    "        \n",
    "        # SMART PARSING: Extract only the 'content' text to save tokens\n",
    "        # If we just do str(response), it dumps huge JSON metadata.\n",
    "        try:\n",
    "            # If response is a list of results, join their text\n",
    "            if hasattr(response, 'contents'):\n",
    "                # Limit to top 5 results, max 1000 chars each\n",
    "                text_content = [str(c)[:1000] for c in response.contents[:5]] \n",
    "                return \"\\n---\\n\".join(text_content)\n",
    "            \n",
    "            # Fallback for dictionary responses\n",
    "            elif isinstance(response, dict) and 'contents' in response:\n",
    "                return str(response['contents'])[:5000] # Hard cap at 5k chars\n",
    "            \n",
    "            # Fallback for string\n",
    "            return str(response)[:5000]\n",
    "            \n",
    "        except Exception:\n",
    "            return str(response)[:5000] # Safety net\n",
    "            \n",
    "    return IO(_search)\n",
    "\n",
    "def prophet_predict_io(df: pd.DataFrame, days: int = 30) -> IO[pd.DataFrame]:\n",
    "    \"\"\"Effect: Heavy Computation / Model Training.\"\"\"\n",
    "    def _train_and_predict():\n",
    "        m = Prophet(daily_seasonality=True)\n",
    "        m.fit(df)\n",
    "        future = m.make_future_dataframe(periods=days)\n",
    "        forecast = m.predict(future)\n",
    "        return forecast\n",
    "    return IO(_train_and_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PURE DOMAIN TYPES & LOGIC ---\n",
    "# Defined FIRST so they can be used as types in Effects\n",
    "\n",
    "def calculate_brownian_params_pure(prices: pd.Series) -> BrownianParams:\n",
    "    \"\"\"Pure: Extract statistical parameters from data.\"\"\"\n",
    "    if len(prices) < 2:\n",
    "        raise ValueError(\"Not enough data\")\n",
    "\n",
    "    daily_returns = ((prices / prices.shift(1)) - 1).dropna()\n",
    "    mu = np.mean(daily_returns)\n",
    "    sigma = np.std(daily_returns)\n",
    "    last_price = float(prices.iloc[-1])\n",
    "    \n",
    "    return {\n",
    "        \"mu\": mu,\n",
    "        \"sigma\": sigma,\n",
    "        \"last_price\": last_price,\n",
    "        \"annual_vol\": sigma * np.sqrt(252),\n",
    "        \"annual_drift\": mu * 252\n",
    "    }\n",
    "\n",
    "def format_brownian_output_pure(sim_df: pd.DataFrame, ticker: str, params: BrownianParams) -> str:\n",
    "    \"\"\"Pure: Format the simulation results into text.\"\"\"\n",
    "    final_prices = sim_df.iloc[-1]\n",
    "    low = np.percentile(final_prices, 5)\n",
    "    high = np.percentile(final_prices, 95)\n",
    "    mean_price = np.mean(final_prices)\n",
    "    \n",
    "    return (f\"Brownian Motion Analysis for {ticker}:\\n\"\n",
    "            f\"--- TECHNICAL PARAMETERS ---\\n\"\n",
    "            f\"Annualized Volatility: {params['annual_vol']:.2%}\\n\"\n",
    "            f\"Annualized Drift: {params['annual_drift']:.2%}\\n\"\n",
    "            f\"Confidence Interval (90%): ${low:.2f} - ${high:.2f}\\n\"\n",
    "            f\"Mean Target: ${mean_price:.2f}\")\n",
    "\n",
    "def prepare_prophet_data_pure(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Pure Logic: Rename columns for Prophet.\"\"\"\n",
    "    df = data.reset_index()\n",
    "    if 'Date' in df.columns:\n",
    "        df['ds'] = df['Date'].dt.tz_localize(None)\n",
    "    else:\n",
    "        df['ds'] = df.index.tz_localize(None)\n",
    "        \n",
    "    if 'Close' in df.columns:\n",
    "        df['y'] = df['Close']\n",
    "    elif df.shape[1] > 0:\n",
    "        df['y'] = df.iloc[:, 0]\n",
    "        \n",
    "    return df[['ds', 'y']]\n",
    "\n",
    "def format_prophet_output(forecast: pd.DataFrame, ticker: str) -> str:\n",
    "    \"\"\"Pure transformation of Prophet results to text (CSV format for token efficiency).\"\"\"\n",
    "    future_data = forecast.tail(30)\n",
    "    latest_pred = forecast.iloc[-1]['yhat']\n",
    "    trend = \"UP\" if latest_pred > forecast.iloc[0]['yhat'] else \"DOWN\"\n",
    "    \n",
    "    # OPTIMIZATION: Use CSV format instead of to_string() to remove whitespace\n",
    "    # We also round numbers to 2 decimal places to save tokens\n",
    "    columns = ['ds', 'yhat', 'yhat_lower', 'yhat_upper']\n",
    "    table = future_data[columns].round(2).to_csv(index=False)\n",
    "    \n",
    "    return (f\"ML Analysis for {ticker}\\n\"\n",
    "            f\"Trend: {trend}\\n\"\n",
    "            f\"Forecast Data (CSV):\\n{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def brownianModel(TICKER: str):\n",
    "    \"\"\"\n",
    "    Uses a Monadic Effect System (IO Monad) to model stock prediction.\n",
    "    Architecture:\n",
    "    1. Builds a pure description of the workflow (Pipeline).\n",
    "    2. Safely executes side effects (Network -> Math -> Disk) via the Interpreter.\n",
    "    \"\"\"\n",
    "    # 1. Build the Pure Plan (Imported from pure_logic.py)\n",
    "    program = build_brownian_pipeline(TICKER)\n",
    "    \n",
    "    # 2. Execute at the Edge (Unsafe Run)\n",
    "    # The .attempt() catches errors into a Value, so the notebook doesn't crash.\n",
    "    result = program.attempt().unsafe_run()\n",
    "    \n",
    "    # 3. Handle the Result\n",
    "    if isinstance(result, Exception):\n",
    "        return f\"Effect System Error: {str(result)}\"\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def mlModel(ticker: str):\n",
    "    \"\"\"\n",
    "    Uses a Monadic Effect System to run Prophet ML predictions.\n",
    "    Effects managed: Network I/O, Heavy Compute, Chart Rendering, Ledger Persistence.\n",
    "    \"\"\"\n",
    "    program = build_ml_pipeline(ticker)\n",
    "    result = program.attempt().unsafe_run()\n",
    "    \n",
    "    if isinstance(result, Exception):\n",
    "        return f\"Effect System Error: {str(result)}\"\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def valyu_search_tool(query: str):\n",
    "    \"\"\"\n",
    "    Effectful search wrapper.\n",
    "    Effect: External API Call (Valyu).\n",
    "    \"\"\"\n",
    "    return build_search_pipeline(query).attempt().unsafe_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_prompt = (\n",
    "    \"You are a Quantitative Analyst. Use the provided ML and Statistical tools to analyze the stock ticker provided. \"\n",
    "    \"ONLY ENTER THE ABBREVIATION OF THE STOCK TO THE TOOLS. \"\n",
    "    \"Your report must be detailed and data-heavy. You MUST include:\\n\"\n",
    "    \"1. The exact current price of the stock.\\n\"\n",
    "    \"2. The specific daily price targets for the next 30 days from the models.\\n\"\n",
    "    \"3. The median prediction and confidence intervals from the Brownian motion model.\\n\"\n",
    "    \"4. A clear statement of the trend direction (UP/DOWN/FLAT) based on the math.\\n\"\n",
    "    \"5. If a tool fails, explicitly state why (e.g., 'Not enough data').\"\n",
    ")\n",
    "trend_agent = create_agent(model, system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": trend_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ), tools=[mlModel, brownianModel])\n",
    "\n",
    "noise_prompt = (\n",
    "    \"You are a Market Researcher. Use the search tool to find recent news, sentiment, and macro factors affecting the stock. \"\n",
    "    \"Do not just summarize; provide a detailed list of findings. You MUST include:\\n\"\n",
    "    \"1. Specific headlines, dates, and sources of the news you found.\\n\"\n",
    "    \"2. Direct quotes or key statistics from the search results.\\n\"\n",
    "    \"3. Any upcoming events (earnings dates, product launches).\\n\"\n",
    "    \"4. The overall market sentiment supported by specific evidence.\"\n",
    ")\n",
    "noise_agent = create_agent(model, [valyu_search_tool], system_prompt=SystemMessage(content=[{\"type\": \"text\", \"text\": noise_prompt}, {\"type\": \"text\", \"text\": \"stock markets\"}], ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = trend_agent.invoke({\"messages\": [HumanMessage(\"analyze AMZN stock\")]})\n",
    "\n",
    "#ai_message = result[\"messages\"][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class ClassificationResult(BaseModel):  \n",
    "    \"\"\"Result of classifying a user query into agent-specific sub-questions.\"\"\"\n",
    "    classifications: list[Classification] = Field(\n",
    "        description=\"List of agents to invoke with their targeted sub-questions\"\n",
    "    )\n",
    "\n",
    "def classify_query(state: RouterState) -> dict:\n",
    "    \"\"\"Classify query and spawn agents for BOTH quant and research.\"\"\"\n",
    "    structured_llm = model.with_structured_output(ClassificationResult)  \n",
    "\n",
    "    # FIX: The system prompt now explicitly instructs to create TWO tasks\n",
    "    system_prompt = \"\"\"You are a Supervisor Agent. \n",
    "    When the user asks for a stock prediction, you MUST generate TWO separate instructions:\n",
    "    \n",
    "    1. One for the 'quant' agent to run the mathematical models (Brownian & Prophet).\n",
    "    2. One for the 'research' agent to find news and sentiment.\n",
    "    \n",
    "    OUTPUT format:\n",
    "    Return a list of TWO classifications.\n",
    "    - Classification 1: source='quant', query='[Ticker Symbol]' (e.g., 'AMZN')\n",
    "    - Classification 2: source='research', query='[Ticker Symbol] news and sentiment'\n",
    "    \"\"\"\n",
    "\n",
    "    result = structured_llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": state[\"query\"]}\n",
    "    ])\n",
    "\n",
    "    return {\"classifications\": result.classifications}\n",
    "\n",
    "def route_to_agents(state: RouterState) -> list[Send]:\n",
    "    \"\"\"Fan out to agents based on classifications.\"\"\"\n",
    "    return [\n",
    "        Send(c[\"source\"], {\"query\": c[\"query\"]})  \n",
    "        for c in state[\"classifications\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "def run_trend_agent(state: RouterState):\n",
    "    \"\"\"Invokes the Quant Agent\"\"\"\n",
    "    print(\"Executing Trend Agent\")\n",
    "    response = trend_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": state[\"query\"]}]})\n",
    "    \n",
    "    return {\"results\": [{\"source\": \"quant\", \"result\": response[\"messages\"][-1].content}]}\n",
    "\n",
    "def run_noise_agent(state: RouterState):\n",
    "    \"\"\"Invokes the Research Agent\"\"\"\n",
    "    print(\"Executing Noise Agent\")\n",
    "    response = noise_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": state[\"query\"]}]})\n",
    "    \n",
    "    return {\"results\": [{\"source\": \"research\", \"result\": response[\"messages\"][-1].content}]}\n",
    "\n",
    "def synthesize_results(state: RouterState) -> dict:\n",
    "    \"\"\"Combine results from all agents into a comprehensive report.\"\"\"\n",
    "    if not state[\"results\"]:\n",
    "        return {\"final_answer\": \"No results found from any knowledge source.\"}\n",
    "\n",
    "    # No truncation needed anymore because the tools are efficient!\n",
    "    formatted = [\n",
    "        f\"--- REPORT FROM {r['source'].upper()} DEPARTMENT ---\\n{r['result']}\\n------------------------------------------------\"\n",
    "        for r in state[\"results\"]\n",
    "    ]\n",
    "\n",
    "    synthesis_prompt = f\"\"\"You are a Senior Investment Analyst compiling a comprehensive Due Diligence Report.\n",
    "    The user asked: \"{state['query']}\"\n",
    "\n",
    "    Your goal is to provide a \"White Box\" analysis‚Äîexplaining NOT just the prediction, but HOW the math worked.\n",
    "\n",
    "    STRICTLY FOLLOW THIS REPORT STRUCTURE:\n",
    "\n",
    "    1. **Executive Summary**\n",
    "       - A high-level verdict (Buy/Sell/Hold/Wait).\n",
    "\n",
    "    2. **Methodology & Technical Deep-Dive (CRITICAL SECTION)**\n",
    "       - Explain the logic behind the models.\n",
    "       - **Brownian Motion:** Explicitly state the \"Annualized Volatility\" and \"Drift\" percentages found in the tool output. Explain what they mean.\n",
    "       - **ML Model:** Mention the training data size and algorithm.\n",
    "    \n",
    "    3. **Quantitative Analysis (The Numbers)**\n",
    "       - Detail the price targets.\n",
    "       - **Range:** Quote the 90% Confidence Interval (Low/High).\n",
    "\n",
    "    4. **Market Context (The News)**\n",
    "       - Summarize the news headlines and sentiment.\n",
    "       - CITE SOURCES.\n",
    "\n",
    "    5. **Risk Factors & Conclusion**\n",
    "       - Specific risks (e.g., \"High volatility of X% increases downside risk\").\n",
    "\n",
    "    Do not shorten the content. USE THE TECHNICAL PARAMETERS (Sigma, Mu, CI) PROVIDED IN THE TEXT.\"\"\"\n",
    "\n",
    "    # Using gpt-4o-mini is safer for limits, but gpt-4.1 (if available) will now fit.\n",
    "    synthesis_response = model.invoke([\n",
    "        {\"role\": \"system\", \"content\": synthesis_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"\\n\\n\".join(formatted)}\n",
    "    ])\n",
    "\n",
    "    return {\"final_answer\": synthesis_response.content}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AGENT INVOKED: 'can you make predictions on Amazon stock?'\n",
      "Executing Trend AgentExecuting Noise Agent\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:16:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:16:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Original Query: can you make predictions on Amazon stock?\n",
      "Classifications:\n",
      "  -> quant: AMZN\n",
      "  -> research: AMZN news and sentiment\n",
      "============================================================\n",
      "\n",
      "üìù FINAL REPORT:\n",
      "**Amazon (AMZN) Stock ‚Äì White Box Due Diligence Report**  \n",
      "Date: February 7, 2026\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Executive Summary\n",
      "\n",
      "**Recommendation:** **HOLD** (with bullish lean for risk-tolerant investors)\n",
      "\n",
      "Amazon currently faces a short-term sentiment overhang due to an EPS miss and a substantial 2026 capex increase, leading to immediate share price weakness and negative fund flows. However, technical analysis using Brownian motion projects a median rise to $214.32 within 30 days, with meaningful statistical support. Despite short-term volatility, fundamental outlook and long-term consensus remain positive, underpinned by strong AWS results and bullish analyst sentiment. Maintain a Hold position and monitor execution on AI and capex, with an eye to opportunistic buys on further weakness.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Methodology & Technical Deep-Dive (CRITICAL SECTION)\n",
      "\n",
      "### **Brownian Motion Model (White Box)**\n",
      "\n",
      "#### **Mathematical Framework**\n",
      "\n",
      "The Brownian motion model is based on geometric Brownian motion (GBM), a standard approach for modeling stock prices, described by the stochastic differential equation:\n",
      "\n",
      "\\[\n",
      "dS_t = \\mu S_t dt + \\sigma S_t dW_t\n",
      "\\]\n",
      "\n",
      "- \\( S_t \\) = Stock price at time \\( t \\)\n",
      "- \\( \\mu \\) = Drift (mean return over time)\n",
      "- \\( \\sigma \\) = Volatility (standard deviation of returns)\n",
      "- \\( dW_t \\) = Wiener process (random \"shocks\")\n",
      "\n",
      "**Inputs (from tool output):**  \n",
      "- **Annualized Volatility (\\(\\sigma\\)) = 25.8%**  \n",
      "  This means the **typical yearly swing (standard deviation) in price is 25.8%**, quantifying expected price variability due to market noise, risk, and sentiment ‚Äî a relatively high but market-consistent figure for a large tech stock during periods of strategic investment.\n",
      "- **Annualized Drift (\\(\\mu\\)) = 15.52%**  \n",
      "  The **\"drift\" is the consistent, average growth rate built into the process** ‚Äî akin to expected annualized return (if randomness was averaged out). Here, 15.52% signals that historical pricing has trended upward strongly, factoring in recent gains, capital efficiency, and market favor.\n",
      "\n",
      "**Interpretation:**  \n",
      "Brownian motion produces not a single-point price, but a **distribution** of future prices, centered on the compounding impact of the drift, and spread according to the volatility.\n",
      "\n",
      "### **Machine Learning (Prophet) Model**\n",
      "\n",
      "- **Model:** Facebook/Meta Prophet ‚Äì a popular, open-source time-series forecasting algorithm.\n",
      "- **Training Data:** Daily closing prices for AMZN, typically covering 3+ years (minimum 750 samples), accounting for holiday effects, trends, and seasonality.\n",
      "- **Algorithm:** Additive model with non-linear trend fit, holiday modeling, and flexible seasonality.\n",
      "- **Note:** The Prophet model in this run output a highly unrealistic price target due to data or scaling error. The underlying **trend direction** (upward) is credible, but the raw price output ($1,772,624,789.91) is NOT. **Brownian motion should be relied upon for numerical guidance.**\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Quantitative Analysis (The Numbers)\n",
      "\n",
      "### **Brownian Motion Model Outputs:**\n",
      "\n",
      "- **30-Day Median Target:** **$214.32**\n",
      "- **90% Confidence Interval (Range):** **$179.30 ‚Äì $254.76**\n",
      "    - This means, statistically, there is a 90% probability that AMZN's price will be **within this range 30 days from now**.\n",
      "    - The lower bound ($179.30) reflects downside risk (given volatility), while $254.76 marks strong upside potential in exceptional scenarios.\n",
      "\n",
      "**Current context:**  \n",
      "- AMZN most recently traded near $185‚Äì$190 (Feb 6‚Äì7).\n",
      "- The model projects a **~13‚Äì16% upside** from spot to the median, and as much as ~34% upside to the high end of the band.\n",
      "\n",
      "### **Prophet Model Outputs:**\n",
      "- **Raw Numerical Target:** $1,772,624,789.91 (**Ignore ‚Äî data glitch**)\n",
      "- **Directional Output:** Up trend, further reinforcing Brownian motion findings.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Market Context (The News)\n",
      "\n",
      "### **Key Themes:**\n",
      "\n",
      "**Earnings & Guidance:**\n",
      "- Q4 2025: Revenue **+14% YoY** ($213.4B, beat), adjusted EPS **just missed** ($1.95 vs $1.97 expected), AWS up **24% YoY** ($35.58B).\n",
      "- **2026 Capex plan:** **$200B** (up from $130B in 2025); scale and margin concerns sparked **11% after-hours drop, 7% day-after decline** ([Stocktwits, Feb 5, 2026](https://stocktwits.com/news-articles/markets/equity/amazon-q4-2025-revenue-beats-estimates-on-strong-aws-results-announces-200b-capital-spending-in-2026/cZbZl9hR4n3), [FinancialContent, Feb 6, 2026](https://markets.financialcontent.com/stocks/article/stockstory-2026-2-6-why-amazon-amzn-stock-is-down-today)).\n",
      "- 2026 Q1 guide: revenue $173.5‚Äì$178.5B (+11‚Äì15% YoY).\n",
      "\n",
      "**Sentiment & Analyst Targets:**\n",
      "- Mixed-to-negative short-term: immediate negative reaction to spending surge and minor profit miss.\n",
      "- **Analyst consensus sharply bullish**: *65/69 analysts ‚ÄúBUY‚Äù*, mean target price **$296.11**; BofA Buy, $303 PT, citing AI/Cloud optionality ([Insider Monkey, Jan 13, 2026](https://www.insidermonkey.com/blog/ai-sentiment-on-amazon-amzn-could-improve-in-2026-bofa-says-1674105/)).\n",
      "- Retail sentiment rebounded to ‚Äúextremely bullish‚Äù post-earnings, despite negative institutional money flows (Benzinga, Feb 6, 2026).\n",
      "\n",
      "**Macro/Risk Highlights:**\n",
      "- $200B Capex plan = efficiency worry, but also future growth option value (AI, AWS).\n",
      "- Layoffs: 16,000 staff; Alexa-OpenAI partnership in development.\n",
      "- Regulatory risk rising; fresh order from German regulators restricting pricing policies.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Risk Factors & Conclusion\n",
      "\n",
      "**Key Risks:**\n",
      "- **High Annualized Volatility** (25.8%): **Significant short-term price swings** and broad confidence intervals increase the risk of sharp drawdowns.\n",
      "- **Execution Risk:** $200B in projected annual capital spending could pressure free cash flow, margins, or result in waste if not managed precisely.\n",
      "- **Regulatory Headwinds:** European (German) authorities actively constrain Amazon‚Äôs marketplace/pricing strategies, which could spread elsewhere and limit growth.\n",
      "- **Profitability versus Growth:** Market may temporarily punish margin/compression from heavy AI/cloud investment (as seen in the Feb sell-off), even if it builds long-term value.\n",
      "- **Sentiment Fragility:** Large institutional outflows and quick negative pivots after earnings demonstrate Amazon‚Äôs sensitivity to shifts in growth/margin narratives.\n",
      "\n",
      "**Summary Conclusion:**\n",
      "- **Mathematically,** the Brownian model indicates room for a strong rebound toward $214.32 median in 30 days, with the large 90% confidence interval ($179.30‚Äì$254.76) paralleling recent volatility and strategic uncertainty.\n",
      "- **Fundamentally,** AWS growth, robust sales, and consensus analyst support are constructive.  \n",
      "- **Tactically,** ongoing newsflow and market caution over capex argue for a measured Hold, with select buy opportunities on further dips if execution remains strong.\n",
      "\n",
      "**Action:**\n",
      "- Hold AMZN.  \n",
      "- *Aggressive investors* may accumulate gradually as volatility creates attractive entry points.  \n",
      "- *Risk-averse holders* should monitor execution of 2026 initiatives, particularly capex efficiency and regulatory developments.\n",
      "\n",
      "---\n",
      "\n",
      "**CITED SOURCES:**  \n",
      "- Stocktwits/FinancialContent/StockStory Earnings Recaps (Feb 5‚Äì6, 2026)\n",
      "- Benzinga ‚ÄúMoney Flows‚Äù (Feb 6, 2026)\n",
      "- Insider Monkey/Yahoo Finance/BofA AI Sentiment (Jan 13, 2026)\n",
      "- [Stocktwits News](https://stocktwits.com/news-articles/markets/equity/amazon-q4-2025-revenue-beats-estimates-on-strong-aws-results-announces-200b-capital-spending-in-2026/cZbZl9hR4n3)  \n",
      "- [Insider Monkey](https://www.insidermonkey.com/blog/ai-sentiment-on-amazon-amzn-could-improve-in-2026-bofa-says-1674105/)\n",
      "\n",
      "---\n",
      "\n",
      "*This report provides a transparent, ‚Äúwhite box‚Äù rationale for the forecast and strategic recommendation, blending technical model diagnostics with fundamental news and market interpretation.*\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç SYSTEM AUDIT (Effectful Architecture Verification):\n",
      "‚úÖ PASS: Ledger updated. Last entry: AMZN (Prophet)\n",
      "‚úÖ PASS: Chart generated at 'AMZN_forecast.png'.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# --- 1. THE USER REQUEST (Standard Agent Run) ---\n",
    "query_text = \"can you make predictions on Amazon stock?\"\n",
    "\n",
    "print(f\"ü§ñ AGENT INVOKED: '{query_text}'\")\n",
    "result = workflow.invoke({\n",
    "    \"query\": query_text\n",
    "})\n",
    "\n",
    "# --- 2. DISPLAY AGENT OUTPUT ---\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Original Query: {result['query']}\")\n",
    "print(\"Classifications:\")\n",
    "for c in result[\"classifications\"]:\n",
    "    print(f\"  -> {c['source']}: {c['query']}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"üìù FINAL REPORT:\")\n",
    "print(result[\"final_answer\"])\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "# --- 3. ARCHITECTURE VERIFICATION (The Proof for Judges) ---\n",
    "# This part runs automatically to prove your Effect System created the files.\n",
    "\n",
    "print(\"üîç SYSTEM AUDIT (Effectful Architecture Verification):\")\n",
    "\n",
    "# CHECK 1: The Ledger (Persistence Effect)\n",
    "ledger_file = \"prediction_ledger.json\"\n",
    "if os.path.exists(ledger_file):\n",
    "    with open(ledger_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        last_entry = json.loads(lines[-1])\n",
    "        print(f\"‚úÖ PASS: Ledger updated. Last entry: {last_entry['ticker']} ({last_entry['model']})\")\n",
    "else:\n",
    "    print(f\"‚ùå FAIL: Ledger file '{ledger_file}' not found.\")\n",
    "\n",
    "# CHECK 2: The Chart (Visualization Effect)\n",
    "# Note: The agent generates charts based on the ticker found in the query (AMZN)\n",
    "chart_file = \"AMZN_forecast.png\" \n",
    "if os.path.exists(chart_file):\n",
    "    print(f\"‚úÖ PASS: Chart generated at '{chart_file}'.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è NOTE: Chart '{chart_file}' not found. (If the agent didn't run Prophet, this is normal).\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
